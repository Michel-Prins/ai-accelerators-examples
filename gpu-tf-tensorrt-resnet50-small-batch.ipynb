{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example was tested on the following NVIDIA Docker image: nvcr.io/nvidia/tensorflow:20.08-tf2-py3\n",
    "# !nvidia-docker run --shm-size 8g --ulimit memlock=-1 -it -v $PWD:/examples -v ~/.aws/:/.aws --network=host nvcr.io/nvidia/tensorflow:20.08-tf2-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your imagenet TFRecord using the following:\n",
    "# https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip -q\n",
    "# !pip install matplotlib pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "\n",
    "from tensorflow.compiler.tf2tensorrt.wrap_py_utils import get_linked_tensorrt_version\n",
    "\n",
    "print(f\"TensorRT version: {get_linked_tensorrt_version()}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = None\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Keras Resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_save_resnet50_model(saved_model_dir = 'resnet50_saved_model'):\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "    model.save(saved_model_dir, include_optimizer=False, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = 'resnet50_saved_model' \n",
    "load_save_resnet50_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/examples/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=8)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using GPU + Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(saved_model_dir)\n",
    "display_every = 5000\n",
    "display_threshold = display_every\n",
    "\n",
    "pred_labels = []\n",
    "actual_labels = []\n",
    "iter_times = []\n",
    "\n",
    "# Get the tf.data.TFRecordDataset object for the ImageNet2012 validation dataset\n",
    "dataset = get_dataset(batch_size)  \n",
    "\n",
    "walltime_start = time.time()\n",
    "for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "    start_time = time.time()\n",
    "    pred_prob_keras = model(validation_ds)\n",
    "    iter_times.append(time.time() - start_time)\n",
    "    \n",
    "    actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "    pred_labels.extend(list(np.argmax(pred_prob_keras, axis=1)))\n",
    "    \n",
    "    if i*batch_size >= display_threshold:\n",
    "        print(f'Images {i*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "        display_threshold+=display_every\n",
    "\n",
    "iter_times = np.array(iter_times)\n",
    "acc_keras_gpu = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "\n",
    "results = pd.DataFrame(columns = [f'keras_gpu_{batch_size}'])\n",
    "results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "results.loc['user_batch_size']         = [batch_size]\n",
    "results.loc['accuracy']                = [acc_keras_gpu]\n",
    "results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using GPU + TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn(batch_size, dataset):\n",
    "    for i, (build_image, _, _) in enumerate(dataset):\n",
    "        if i > 1:\n",
    "            break\n",
    "        yield (build_image,)\n",
    "\n",
    "def calibrate_fn(n_calib, batch_size, dataset):\n",
    "    for i, (calib_image, _, _) in enumerate(dataset):\n",
    "        if i > n_calib // batch_size:\n",
    "            break\n",
    "        yield (calib_image,)\n",
    "\n",
    "def build_tensorrt_engine(precision, batch_size, dataset):\n",
    "    from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "    conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=precision.upper(),\n",
    "                                                                   max_workspace_size_bytes=(1<<32),\n",
    "                                                                   maximum_cached_engines=2)\n",
    "    converter = trt.TrtGraphConverterV2(input_saved_model_dir='resnet50_saved_model',\n",
    "                                        conversion_params=conversion_params)\n",
    "    \n",
    "    if precision.lower() == 'int8':\n",
    "        n_calib=100\n",
    "        converter.convert(calibration_input_fn=partial(calibrate_fn, n_calib, batch_size, \n",
    "                                                       dataset.shuffle(buffer_size=n_calib, reshuffle_each_iteration=True)))\n",
    "    else:\n",
    "        converter.convert()\n",
    "        \n",
    "    trt_compiled_model_dir = f'resnet50_trt_saved_models/resnet50_{precision}_{batch_size}'\n",
    "    shutil.rmtree(trt_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    converter.build(input_fn=partial(build_fn, batch_size, dataset))\n",
    "    converter.save(output_saved_model_dir=trt_compiled_model_dir)\n",
    "    print(f'\\nOptimized for {precision} and batch size {batch_size}, directory:{trt_compiled_model_dir}\\n')\n",
    "    return trt_compiled_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_predict_benchmark(precision, batch_size, use_cache=False, display_every=100, warm_up=10):\n",
    "\n",
    "    print('\\n=======================================================')\n",
    "    print(f'Benchmark results for precision: {precision}, batch size: {batch_size}')\n",
    "    print('=======================================================\\n')\n",
    "    \n",
    "    dataset = get_dataset(batch_size)\n",
    "    \n",
    "    # If caching is enabled, cache dataset for better i/o performance\n",
    "    if use_cache:\n",
    "        print('Caching dataset ...')\n",
    "        start_time = time.time()\n",
    "        for (img,_,_) in dataset:\n",
    "            continue\n",
    "        print(f'Finished caching {time.time() - start_time}')\n",
    "    \n",
    "    trt_compiled_model_dir = build_tensorrt_engine(precision, batch_size, dataset)\n",
    "    saved_model_trt = tf.saved_model.load(trt_compiled_model_dir, tags=[tag_constants.SERVING])\n",
    "    model_trt = saved_model_trt.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "    \n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    iter_times = []\n",
    "    \n",
    "    display_every = 5000\n",
    "    display_threshold = display_every\n",
    "    initial_time = time.time()\n",
    "    \n",
    "    walltime_start = time.time()\n",
    "    for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "        if i==0:\n",
    "            for w in range(warm_up):\n",
    "                _ = model_trt(validation_ds);\n",
    "                \n",
    "        start_time = time.time()\n",
    "        trt_results = model_trt(validation_ds);\n",
    "        iter_times.append(time.time() - start_time)\n",
    "        \n",
    "        actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "        pred_labels.extend(list(tf.argmax(trt_results['predictions'], axis=1).numpy()))\n",
    "        if (i)*batch_size >= display_threshold:\n",
    "            print(f'Images {(i)*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "            display_threshold+=display_every\n",
    "    \n",
    "    print(f'Wall time: {time.time() - walltime_start}')\n",
    "\n",
    "    acc_trt = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "   \n",
    "    results = pd.DataFrame(columns = [f'trt_{precision}_{batch_size}'])\n",
    "    results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "    results.loc['user_batch_size']         = [batch_size]\n",
    "    results.loc['accuracy']                = [acc_trt]\n",
    "    results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]   \n",
    "    results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "    results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "    results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "    results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "    display(results.T)\n",
    "   \n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "bench_options = {\n",
    "    'batch_size': [batch_size],\n",
    "    'precision': ['fp32', 'fp16', 'int8']\n",
    "}\n",
    "\n",
    "bname, bval = zip(*bench_options.items())\n",
    "blist = [dict(zip(bname, h)) for h in itertools.product(*bval)]\n",
    "\n",
    "print('Benchmark sweep combinations:')\n",
    "for b in blist:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ds = pd.DataFrame()\n",
    "\n",
    "if results is None:\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "col_name = lambda boption: f'trt_{boption[\"precision\"]}_{boption[\"batch_size\"]}'\n",
    "\n",
    "for boption in blist:\n",
    "    res, it = trt_predict_benchmark(**boption)\n",
    "    iter_ds = pd.concat([iter_ds, pd.DataFrame(it, columns=[col_name(boption)])], axis=1)\n",
    "    results = pd.concat([results, res], axis=1)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ds.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
