{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU inference with NVIDIA T4 on Amazon EC2 G4 instance\n",
    "This example demonstrates GPU inference with:\n",
    "* GPU accelerated TensorFlow/Keras\n",
    "* NVIDIA TensorRT optimizer and runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was tested on Amazon EC2 `g4dn.xlarge` using the following AWS Deep Learning AMI:\n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "And the following NVIDIA TensorFlow Docker image: \n",
    "`nvcr.io/nvidia/tensorflow:20.08-tf2-py3`\n",
    "\n",
    "Create a Docker container:<br>\n",
    "`nvidia-docker run --shm-size 8g --ulimit memlock=-1 -it -v $PWD:/examples -v ~/.aws/:/.aws --network=host nvcr.io/nvidia/tensorflow:20.08-tf2-py3`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/examples/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip -q\n",
    "# !pip install matplotlib pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT version: (7, 1, 3)\n",
      "TensorFlow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "\n",
    "from tensorflow.compiler.tf2tensorrt.wrap_py_utils import get_linked_tensorrt_version\n",
    "\n",
    "print(f\"TensorRT version: {get_linked_tensorrt_version()}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = None\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Keras Resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_save_resnet50_model(saved_model_dir = 'resnet50_saved_model'):\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "    model.save(saved_model_dir, include_optimizer=False, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: resnet50_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = 'resnet50_saved_model' \n",
    "load_save_resnet50_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `tf.data` to read ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/examples/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using GPU + Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Images 5000/50000. Average i/s 113.52902935209637\n",
      "Images 10000/50000. Average i/s 114.4822357792094\n",
      "Images 15000/50000. Average i/s 114.17100473485702\n",
      "Images 20000/50000. Average i/s 114.61583324110076\n",
      "Images 25000/50000. Average i/s 114.84187563894713\n",
      "Images 30000/50000. Average i/s 115.14781546576788\n",
      "Images 35000/50000. Average i/s 115.10561798972904\n",
      "Images 40000/50000. Average i/s 115.20453046771337\n",
      "Images 45000/50000. Average i/s 115.71023295020717\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keras_gpu_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_type</th>\n",
       "      <td>g4dn.xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.74956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>440.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall_time</th>\n",
       "      <td>443.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>115.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>7.3476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>70.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>84.4612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>69.0285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>62.314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         keras_gpu_8\n",
       "instance_type            g4dn.xlarge\n",
       "user_batch_size                    8\n",
       "accuracy                     0.74956\n",
       "prediction_time              440.113\n",
       "wall_time                    443.712\n",
       "images_per_sec_mean          115.746\n",
       "images_per_sec_std            7.3476\n",
       "latency_mean                  70.418\n",
       "latency_99th_percentile      84.4612\n",
       "latency_median               69.0285\n",
       "latency_min                   62.314"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(saved_model_dir)\n",
    "display_every = 5000\n",
    "display_threshold = display_every\n",
    "\n",
    "pred_labels = []\n",
    "actual_labels = []\n",
    "iter_times = []\n",
    "\n",
    "# Get the tf.data.TFRecordDataset object for the ImageNet2012 validation dataset\n",
    "dataset = get_dataset(batch_size)  \n",
    "\n",
    "walltime_start = time.time()\n",
    "for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "    start_time = time.time()\n",
    "    pred_prob_keras = model(validation_ds)\n",
    "    iter_times.append(time.time() - start_time)\n",
    "    \n",
    "    actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "    pred_labels.extend(list(np.argmax(pred_prob_keras, axis=1)))\n",
    "    \n",
    "    if i*batch_size >= display_threshold:\n",
    "        print(f'Images {i*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "        display_threshold+=display_every\n",
    "\n",
    "iter_times = np.array(iter_times)\n",
    "acc_keras_gpu = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "\n",
    "results = pd.DataFrame(columns = [f'keras_gpu_{batch_size}'])\n",
    "results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "results.loc['user_batch_size']         = [batch_size]\n",
    "results.loc['accuracy']                = [acc_keras_gpu]\n",
    "results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "display(results.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using GPU + TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn(batch_size, dataset):\n",
    "    for i, (build_image, _, _) in enumerate(dataset):\n",
    "        if i > 1:\n",
    "            break\n",
    "        yield (build_image,)\n",
    "\n",
    "def calibrate_fn(n_calib, batch_size, dataset):\n",
    "    for i, (calib_image, _, _) in enumerate(dataset):\n",
    "        if i > n_calib // batch_size:\n",
    "            break\n",
    "        yield (calib_image,)\n",
    "\n",
    "def build_tensorrt_engine(precision, batch_size, dataset):\n",
    "    from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "    conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=precision.upper(),\n",
    "                                                                   max_workspace_size_bytes=(1<<32),\n",
    "                                                                   maximum_cached_engines=2)\n",
    "    converter = trt.TrtGraphConverterV2(input_saved_model_dir='resnet50_saved_model',\n",
    "                                        conversion_params=conversion_params)\n",
    "    \n",
    "    if precision.lower() == 'int8':\n",
    "        n_calib=50\n",
    "        converter.convert(calibration_input_fn=partial(calibrate_fn, n_calib, batch_size, \n",
    "                                                       dataset.shuffle(buffer_size=n_calib, reshuffle_each_iteration=True)))\n",
    "    else:\n",
    "        converter.convert()\n",
    "        \n",
    "    trt_compiled_model_dir = f'resnet50_trt_saved_models/resnet50_{precision}_{batch_size}'\n",
    "    shutil.rmtree(trt_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    converter.build(input_fn=partial(build_fn, batch_size, dataset))\n",
    "    converter.save(output_saved_model_dir=trt_compiled_model_dir)\n",
    "    print(f'\\nOptimized for {precision} and batch size {batch_size}, directory:{trt_compiled_model_dir}\\n')\n",
    "    return trt_compiled_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_predict_benchmark(precision, batch_size, use_cache=False, display_every=100, warm_up=10):\n",
    "\n",
    "    print('\\n=======================================================')\n",
    "    print(f'Benchmark results for precision: {precision}, batch size: {batch_size}')\n",
    "    print('=======================================================\\n')\n",
    "    \n",
    "    dataset = get_dataset(batch_size)\n",
    "    \n",
    "    # If caching is enabled, cache dataset for better i/o performance\n",
    "    if use_cache:\n",
    "        print('Caching dataset ...')\n",
    "        start_time = time.time()\n",
    "        for (img,_,_) in dataset:\n",
    "            continue\n",
    "        print(f'Finished caching {time.time() - start_time}')\n",
    "    \n",
    "    trt_compiled_model_dir = build_tensorrt_engine(precision, batch_size, dataset)\n",
    "    saved_model_trt = tf.saved_model.load(trt_compiled_model_dir, tags=[tag_constants.SERVING])\n",
    "    model_trt = saved_model_trt.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "    \n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    iter_times = []\n",
    "    \n",
    "    display_every = 5000\n",
    "    display_threshold = display_every\n",
    "    initial_time = time.time()\n",
    "    \n",
    "    walltime_start = time.time()\n",
    "    for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "        if i==0:\n",
    "            for w in range(warm_up):\n",
    "                _ = model_trt(validation_ds);\n",
    "                \n",
    "        start_time = time.time()\n",
    "        trt_results = model_trt(validation_ds);\n",
    "        iter_times.append(time.time() - start_time)\n",
    "        \n",
    "        actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "        pred_labels.extend(list(tf.argmax(trt_results['predictions'], axis=1).numpy()))\n",
    "        if (i)*batch_size >= display_threshold:\n",
    "            print(f'Images {(i)*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "            display_threshold+=display_every\n",
    "    \n",
    "    print(f'Wall time: {time.time() - walltime_start}')\n",
    "\n",
    "    acc_trt = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "   \n",
    "    results = pd.DataFrame(columns = [f'trt_{precision}_{batch_size}'])\n",
    "    results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "    results.loc['user_batch_size']         = [batch_size]\n",
    "    results.loc['accuracy']                = [acc_trt]\n",
    "    results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]   \n",
    "    results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "    results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "    results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "    results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "    display(results.T)\n",
    "   \n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark sweep combinations:\n",
      "{'batch_size': 8, 'precision': 'fp32'}\n",
      "{'batch_size': 8, 'precision': 'fp16'}\n",
      "{'batch_size': 8, 'precision': 'int8'}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "bench_options = {\n",
    "    'batch_size': [batch_size],\n",
    "    'precision': ['fp32', 'fp16', 'int8']\n",
    "}\n",
    "\n",
    "bname, bval = zip(*bench_options.items())\n",
    "blist = [dict(zip(bname, h)) for h in itertools.product(*bval)]\n",
    "\n",
    "print('Benchmark sweep combinations:')\n",
    "for b in blist:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for precision: fp32, batch size: 8\n",
      "=======================================================\n",
      "\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Assets written to: resnet50_trt_saved_models/resnet50_fp32_8/assets\n",
      "\n",
      "Optimized for fp32 and batch size 8, directory:resnet50_trt_saved_models/resnet50_fp32_8\n",
      "\n",
      "Images 5000/50000. Average i/s 1706.9338144076587\n",
      "Images 10000/50000. Average i/s 1709.7124824008995\n",
      "Images 15000/50000. Average i/s 1714.181552149894\n",
      "Images 20000/50000. Average i/s 1706.435347541865\n",
      "Images 25000/50000. Average i/s 1694.5647994188168\n",
      "Images 30000/50000. Average i/s 1686.1055872763206\n",
      "Images 35000/50000. Average i/s 1691.5992314594068\n",
      "Images 40000/50000. Average i/s 1690.6736552055474\n",
      "Images 45000/50000. Average i/s 1678.790774983944\n",
      "Wall time: 143.3079001903534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trt_fp32_8</th>\n",
       "      <td>g4dn.xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>38.1336</td>\n",
       "      <td>143.327</td>\n",
       "      <td>1666.69</td>\n",
       "      <td>960.928</td>\n",
       "      <td>6.10138</td>\n",
       "      <td>13.797</td>\n",
       "      <td>5.91063</td>\n",
       "      <td>1.36304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           instance_type user_batch_size accuracy prediction_time wall_time  \\\n",
       "trt_fp32_8   g4dn.xlarge               8  0.74956         38.1336   143.327   \n",
       "\n",
       "           images_per_sec_mean images_per_sec_std latency_mean  \\\n",
       "trt_fp32_8             1666.69            960.928      6.10138   \n",
       "\n",
       "           latency_99th_percentile latency_median latency_min  \n",
       "trt_fp32_8                  13.797        5.91063     1.36304  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for precision: fp16, batch size: 8\n",
      "=======================================================\n",
      "\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).trt_engine_resources.TRTEngineOp_0_0._serialized_trt_resource_filename\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Assets written to: resnet50_trt_saved_models/resnet50_fp16_8/assets\n",
      "\n",
      "Optimized for fp16 and batch size 8, directory:resnet50_trt_saved_models/resnet50_fp16_8\n",
      "\n",
      "Images 5000/50000. Average i/s 1972.9929443064034\n",
      "Images 10000/50000. Average i/s 1931.125588304386\n",
      "Images 15000/50000. Average i/s 1897.5221155505612\n",
      "Images 20000/50000. Average i/s 1897.409528086548\n",
      "Images 25000/50000. Average i/s 1903.1808092268618\n",
      "Images 30000/50000. Average i/s 1907.7603788948525\n",
      "Images 35000/50000. Average i/s 1881.8081660423734\n",
      "Images 40000/50000. Average i/s 1811.5798501140848\n",
      "Images 45000/50000. Average i/s 1725.9618582526007\n",
      "Wall time: 135.05888485908508\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trt_fp16_8</th>\n",
       "      <td>g4dn.xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>0.74968</td>\n",
       "      <td>38.0335</td>\n",
       "      <td>135.078</td>\n",
       "      <td>1707.24</td>\n",
       "      <td>1016.37</td>\n",
       "      <td>6.08536</td>\n",
       "      <td>14.1668</td>\n",
       "      <td>5.91636</td>\n",
       "      <td>1.43266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           instance_type user_batch_size accuracy prediction_time wall_time  \\\n",
       "trt_fp16_8   g4dn.xlarge               8  0.74968         38.0335   135.078   \n",
       "\n",
       "           images_per_sec_mean images_per_sec_std latency_mean  \\\n",
       "trt_fp16_8             1707.24            1016.37      6.08536   \n",
       "\n",
       "           latency_99th_percentile latency_median latency_min  \n",
       "trt_fp16_8                 14.1668        5.91636     1.43266  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for precision: int8, batch size: 8\n",
      "=======================================================\n",
      "\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).trt_engine_resources.TRTEngineOp_1_0._serialized_trt_resource_filename\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Assets written to: resnet50_trt_saved_models/resnet50_int8_8/assets\n",
      "\n",
      "Optimized for int8 and batch size 8, directory:resnet50_trt_saved_models/resnet50_int8_8\n",
      "\n",
      "Images 5000/50000. Average i/s 1879.6287615037268\n",
      "Images 10000/50000. Average i/s 1890.5233308310728\n",
      "Images 15000/50000. Average i/s 1904.7501508674482\n",
      "Images 20000/50000. Average i/s 1898.7457632383791\n",
      "Images 25000/50000. Average i/s 1902.8776155291969\n",
      "Images 30000/50000. Average i/s 1898.16488970591\n",
      "Images 35000/50000. Average i/s 1889.473046700565\n",
      "Images 40000/50000. Average i/s 1894.5937887248815\n",
      "Images 45000/50000. Average i/s 1893.7721136475534\n",
      "Wall time: 133.06834959983826\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trt_int8_8</th>\n",
       "      <td>g4dn.xlarge</td>\n",
       "      <td>8</td>\n",
       "      <td>0.74924</td>\n",
       "      <td>34.3497</td>\n",
       "      <td>133.087</td>\n",
       "      <td>1895.03</td>\n",
       "      <td>1086.22</td>\n",
       "      <td>5.49594</td>\n",
       "      <td>12.2826</td>\n",
       "      <td>5.27298</td>\n",
       "      <td>1.44053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           instance_type user_batch_size accuracy prediction_time wall_time  \\\n",
       "trt_int8_8   g4dn.xlarge               8  0.74924         34.3497   133.087   \n",
       "\n",
       "           images_per_sec_mean images_per_sec_std latency_mean  \\\n",
       "trt_int8_8             1895.03            1086.22      5.49594   \n",
       "\n",
       "           latency_99th_percentile latency_median latency_min  \n",
       "trt_int8_8                 12.2826        5.27298     1.44053  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keras_gpu_8</th>\n",
       "      <th>trt_fp32_8</th>\n",
       "      <th>trt_fp16_8</th>\n",
       "      <th>trt_int8_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_type</th>\n",
       "      <td>g4dn.xlarge</td>\n",
       "      <td>g4dn.xlarge</td>\n",
       "      <td>g4dn.xlarge</td>\n",
       "      <td>g4dn.xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.74956</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>0.74968</td>\n",
       "      <td>0.74924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>440.113</td>\n",
       "      <td>38.1336</td>\n",
       "      <td>38.0335</td>\n",
       "      <td>34.3497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall_time</th>\n",
       "      <td>443.712</td>\n",
       "      <td>143.327</td>\n",
       "      <td>135.078</td>\n",
       "      <td>133.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>115.746</td>\n",
       "      <td>1666.69</td>\n",
       "      <td>1707.24</td>\n",
       "      <td>1895.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>7.3476</td>\n",
       "      <td>960.928</td>\n",
       "      <td>1016.37</td>\n",
       "      <td>1086.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>70.418</td>\n",
       "      <td>6.10138</td>\n",
       "      <td>6.08536</td>\n",
       "      <td>5.49594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>84.4612</td>\n",
       "      <td>13.797</td>\n",
       "      <td>14.1668</td>\n",
       "      <td>12.2826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>69.0285</td>\n",
       "      <td>5.91063</td>\n",
       "      <td>5.91636</td>\n",
       "      <td>5.27298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>62.314</td>\n",
       "      <td>1.36304</td>\n",
       "      <td>1.43266</td>\n",
       "      <td>1.44053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         keras_gpu_8   trt_fp32_8   trt_fp16_8   trt_int8_8\n",
       "instance_type            g4dn.xlarge  g4dn.xlarge  g4dn.xlarge  g4dn.xlarge\n",
       "user_batch_size                    8            8            8            8\n",
       "accuracy                     0.74956      0.74956      0.74968      0.74924\n",
       "prediction_time              440.113      38.1336      38.0335      34.3497\n",
       "wall_time                    443.712      143.327      135.078      133.087\n",
       "images_per_sec_mean          115.746      1666.69      1707.24      1895.03\n",
       "images_per_sec_std            7.3476      960.928      1016.37      1086.22\n",
       "latency_mean                  70.418      6.10138      6.08536      5.49594\n",
       "latency_99th_percentile      84.4612       13.797      14.1668      12.2826\n",
       "latency_median               69.0285      5.91063      5.91636      5.27298\n",
       "latency_min                   62.314      1.36304      1.43266      1.44053"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_ds = pd.DataFrame()\n",
    "\n",
    "if results is None:\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "col_name = lambda boption: f'trt_{boption[\"precision\"]}_{boption[\"batch_size\"]}'\n",
    "\n",
    "for boption in blist:\n",
    "    res, it = trt_predict_benchmark(**boption)\n",
    "    iter_ds = pd.concat([iter_ds, pd.DataFrame(it, columns=[col_name(boption)])], axis=1)\n",
    "    results = pd.concat([results, res], axis=1)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
