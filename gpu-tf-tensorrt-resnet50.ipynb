{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example was tested on the following NVIDIA Docker image: nvcr.io/nvidia/tensorflow:20.08-tf2-py3\n",
    "# !nvidia-docker run --shm-size 8g --ulimit memlock=-1 -it -v $PWD:/examples -v ~/.aws/:/.aws --network=host nvcr.io/nvidia/tensorflow:20.08-tf2-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your imagenet TFRecord using the following:\n",
    "# https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip -q\n",
    "# !pip install matplotlib pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT version: (7, 1, 3)\n",
      "TensorFlow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "\n",
    "from tensorflow.compiler.tf2tensorrt.wrap_py_utils import get_linked_tensorrt_version\n",
    "print(f\"TensorRT version: {get_linked_tensorrt_version()}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Keras Resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_save_resnet50_model(saved_model_dir = 'resnet50_saved_model'):\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "    model.save(saved_model_dir, include_optimizer=False, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = 'resnet50_saved_model' \n",
    "# load_save_resnet50_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/examples/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=8)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using GPU + Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Images 5120/50000. Average i/s 1147.8297225075496\n",
      "Images 10112/50000. Average i/s 1193.3223289280056\n",
      "Images 15104/50000. Average i/s 1210.2069520020327\n",
      "Images 20096/50000. Average i/s 1217.330973253321\n",
      "Images 25088/50000. Average i/s 1222.4490063275996\n",
      "Images 30080/50000. Average i/s 1224.0327295058119\n",
      "Images 35072/50000. Average i/s 1226.6877457649105\n",
      "Images 40064/50000. Average i/s 1228.7571411064814\n",
      "Images 45056/50000. Average i/s 1230.6350936628844\n",
      "CPU times: user 10min 4s, sys: 58.3 s, total: 11min 2s\n",
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = tf.keras.models.load_model(saved_model_dir)\n",
    "batch_size = 128\n",
    "display_every = 5000\n",
    "display_threshold = display_every\n",
    "\n",
    "pred_labels = []\n",
    "actual_labels = []\n",
    "iter_times = []\n",
    "\n",
    "# Get the tf.data.TFRecordDataset object for the ImageNet2012 validation dataset\n",
    "dataset = get_dataset(batch_size)  \n",
    "\n",
    "for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "    start_time = time.time()\n",
    "    pred_prob_keras = model(validation_ds)\n",
    "    iter_times.append(time.time() - start_time)\n",
    "       \n",
    "    actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "    pred_labels.extend(list(np.argmax(pred_prob_keras, axis=1)))\n",
    "    \n",
    "    if i*batch_size >= display_threshold:\n",
    "        print(f'Images {i*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "        display_threshold+=display_every\n",
    "\n",
    "iter_times = np.array(iter_times)\n",
    "acc_keras_gpu = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keras_gpu_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_type</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.74956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>48.3395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>1230.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>122.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>123.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>116.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>103.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>76.3261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        keras_gpu_128\n",
       "instance_type            g4dn.2xlarge\n",
       "user_batch_size                   128\n",
       "accuracy                      0.74956\n",
       "prediction_time               48.3395\n",
       "images_per_sec_mean           1230.24\n",
       "images_per_sec_std            122.924\n",
       "latency_mean                  123.631\n",
       "latency_99th_percentile       116.459\n",
       "latency_median                103.451\n",
       "latency_min                   76.3261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns = [f'keras_gpu_{batch_size}'])\n",
    "results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "results.loc['user_batch_size']         = [batch_size]\n",
    "results.loc['accuracy']                = [acc_keras_gpu]\n",
    "results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using GPU + TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn(batch_size, dataset):\n",
    "    for i, (build_image, _, _) in enumerate(dataset):\n",
    "        if i > 1:\n",
    "            break\n",
    "        yield (build_image,)\n",
    "\n",
    "def calibrate_fn(n_calib, batch_size, dataset):\n",
    "    for i, (calib_image, _, _) in enumerate(dataset):\n",
    "        if i > n_calib // batch_size:\n",
    "            break\n",
    "        yield (calib_image,)\n",
    "\n",
    "def build_tensorrt_engine(precision, batch_size, dataset):\n",
    "    from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "    conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=precision.upper(),\n",
    "                                                                   max_workspace_size_bytes=(1<<32),\n",
    "                                                                   maximum_cached_engines=2)\n",
    "    converter = trt.TrtGraphConverterV2(input_saved_model_dir='resnet50_saved_model',\n",
    "                                        conversion_params=conversion_params)\n",
    "    \n",
    "    if precision.lower() == 'int8':\n",
    "        n_calib=100\n",
    "        converter.convert(calibration_input_fn=partial(calibrate_fn, n_calib, batch_size, \n",
    "                                                       dataset.shuffle(buffer_size=n_calib, reshuffle_each_iteration=True)))\n",
    "    else:\n",
    "        converter.convert()\n",
    "        \n",
    "    trt_compiled_model_dir = f'resnet50_trt_saved_models/resnet50_{precision}_{batch_size}'\n",
    "    shutil.rmtree(trt_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    converter.build(input_fn=partial(build_fn, batch_size, dataset))\n",
    "    converter.save(output_saved_model_dir=trt_compiled_model_dir)\n",
    "    print(f'\\nOptimized for {precision} and batch size {batch_size}, directory:{trt_compiled_model_dir}\\n')\n",
    "    return trt_compiled_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_predict_benchmark(precision, batch_size, use_cache=False, display_every=100, warm_up=10):\n",
    "\n",
    "    print('\\n=======================================================')\n",
    "    print(f'Benchmark results for precision: {precision}, batch size: {batch_size}')\n",
    "    print('=======================================================\\n')\n",
    "    \n",
    "    dataset = get_dataset(batch_size)\n",
    "    \n",
    "    # If caching is enabled, cache dataset for better i/o performance\n",
    "    if use_cache:\n",
    "        print('Caching dataset ...')\n",
    "        start_time = time.time()\n",
    "        for (img,_,_) in dataset:\n",
    "            continue\n",
    "        print(f'Finished caching {time.time() - start_time}')\n",
    "    \n",
    "    trt_compiled_model_dir = build_tensorrt_engine(precision, batch_size, dataset)\n",
    "    saved_model_trt = tf.saved_model.load(trt_compiled_model_dir, tags=[tag_constants.SERVING])\n",
    "    model_trt = saved_model_trt.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "    \n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    iter_times = []\n",
    "    \n",
    "    display_every = 5000\n",
    "    display_threshold = display_every\n",
    "    initial_time = time.time()\n",
    "    \n",
    "    walltime_start = time.time()\n",
    "    for i, (validation_ds, label, _) in enumerate(dataset):\n",
    "        if i==0:\n",
    "            for w in range(warm_up):\n",
    "                _ = model_trt(validation_ds);\n",
    "                \n",
    "        start_time = time.time()\n",
    "        trt_results = model_trt(validation_ds);\n",
    "        iter_times.append(time.time() - start_time)\n",
    "\n",
    "        actual_labels.extend(l for k in label.numpy() for l in k)\n",
    "        pred_labels.extend(list(tf.argmax(trt_results['predictions'], axis=1).numpy()))\n",
    "        if (i)*batch_size >= display_threshold:\n",
    "            print(f'Images {(i)*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "            display_threshold+=display_every\n",
    "    \n",
    "    print(f'Wall time: {time.time() - walltime_start}')\n",
    "\n",
    "    acc_trt = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "   \n",
    "    results = pd.DataFrame(columns = [f'trt_{precision}_{batch_size}'])\n",
    "    results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "    results.loc['user_batch_size']         = [batch_size]\n",
    "    results.loc['accuracy']                = [acc_keras_gpu]\n",
    "    results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "    results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "    results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "    results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "    results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "    display(results.T)\n",
    "   \n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark sweep combinations:\n",
      "{'batch_size': 128, 'precision': 'fp32'}\n",
      "{'batch_size': 128, 'precision': 'int8'}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "bench_options = {\n",
    "    'batch_size': [128],\n",
    "    'precision': ['fp32', 'int8']\n",
    "}\n",
    "\n",
    "bname, bval = zip(*bench_options.items())\n",
    "blist = [dict(zip(bname, h)) for h in itertools.product(*bval)]\n",
    "\n",
    "print('Benchmark sweep combinations:')\n",
    "for b in blist:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for precision: fp32, batch size: 128\n",
      "=======================================================\n",
      "\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: resnet50_trt_saved_models/resnet50_fp32_128/assets\n",
      "\n",
      "Optimized for fp32 and batch size 128, directory:resnet50_trt_saved_models/resnet50_fp32_128\n",
      "\n",
      "Images 5120/50000. Average i/s 7702.538681845033\n",
      "Images 10112/50000. Average i/s 7779.474371607978\n",
      "Images 15104/50000. Average i/s 7764.712440110534\n",
      "Images 20096/50000. Average i/s 7798.51319338928\n",
      "Images 25088/50000. Average i/s 7848.34891248762\n",
      "Images 30080/50000. Average i/s 7791.320327800385\n",
      "Images 35072/50000. Average i/s 7759.133058809485\n",
      "Images 40064/50000. Average i/s 7748.949038793968\n",
      "Images 45056/50000. Average i/s 7766.063650091326\n",
      "Wall time: 118.31861662864685\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trt_fp32_128</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>128</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>6.833</td>\n",
       "      <td>7796.18</td>\n",
       "      <td>1292.03</td>\n",
       "      <td>17.4757</td>\n",
       "      <td>24.179</td>\n",
       "      <td>16.1085</td>\n",
       "      <td>8.54301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             instance_type user_batch_size accuracy prediction_time  \\\n",
       "trt_fp32_128  g4dn.2xlarge             128  0.74956           6.833   \n",
       "\n",
       "             images_per_sec_mean images_per_sec_std latency_mean  \\\n",
       "trt_fp32_128             7796.18            1292.03      17.4757   \n",
       "\n",
       "             latency_99th_percentile latency_median latency_min  \n",
       "trt_fp32_128                  24.179        16.1085     8.54301  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for precision: int8, batch size: 128\n",
      "=======================================================\n",
      "\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).trt_engine_resources.TRTEngineOp_0_0._serialized_trt_resource_filename\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Assets written to: resnet50_trt_saved_models/resnet50_int8_128/assets\n",
      "\n",
      "Optimized for int8 and batch size 128, directory:resnet50_trt_saved_models/resnet50_int8_128\n",
      "\n",
      "Images 5120/50000. Average i/s 8878.80057994204\n",
      "Images 10112/50000. Average i/s 9037.153258254486\n",
      "Images 15104/50000. Average i/s 9027.153506157285\n",
      "Images 20096/50000. Average i/s 8959.793644351976\n",
      "Images 25088/50000. Average i/s 8951.881030121463\n",
      "Images 30080/50000. Average i/s 8875.169836871713\n",
      "Images 35072/50000. Average i/s 8860.088702275709\n",
      "Images 40064/50000. Average i/s 8855.28263552897\n",
      "Images 45056/50000. Average i/s 8827.82710469593\n",
      "Wall time: 76.19987201690674\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trt_int8_128</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>128</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>5.73362</td>\n",
       "      <td>8846.93</td>\n",
       "      <td>900.659</td>\n",
       "      <td>14.664</td>\n",
       "      <td>21.6985</td>\n",
       "      <td>13.9563</td>\n",
       "      <td>8.63504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             instance_type user_batch_size accuracy prediction_time  \\\n",
       "trt_int8_128  g4dn.2xlarge             128  0.74956         5.73362   \n",
       "\n",
       "             images_per_sec_mean images_per_sec_std latency_mean  \\\n",
       "trt_int8_128             8846.93            900.659       14.664   \n",
       "\n",
       "             latency_99th_percentile latency_median latency_min  \n",
       "trt_int8_128                 21.6985        13.9563     8.63504  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keras_gpu_128</th>\n",
       "      <th>trt_fp32_128</th>\n",
       "      <th>trt_int8_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_type</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.74956</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>0.74956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>48.3395</td>\n",
       "      <td>6.833</td>\n",
       "      <td>5.73362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>1230.24</td>\n",
       "      <td>7796.18</td>\n",
       "      <td>8846.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>122.924</td>\n",
       "      <td>1292.03</td>\n",
       "      <td>900.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>123.631</td>\n",
       "      <td>17.4757</td>\n",
       "      <td>14.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>116.459</td>\n",
       "      <td>24.179</td>\n",
       "      <td>21.6985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>103.451</td>\n",
       "      <td>16.1085</td>\n",
       "      <td>13.9563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>76.3261</td>\n",
       "      <td>8.54301</td>\n",
       "      <td>8.63504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        keras_gpu_128  trt_fp32_128  trt_int8_128\n",
       "instance_type            g4dn.2xlarge  g4dn.2xlarge  g4dn.2xlarge\n",
       "user_batch_size                   128           128           128\n",
       "accuracy                      0.74956       0.74956       0.74956\n",
       "prediction_time               48.3395         6.833       5.73362\n",
       "images_per_sec_mean           1230.24       7796.18       8846.93\n",
       "images_per_sec_std            122.924       1292.03       900.659\n",
       "latency_mean                  123.631       17.4757        14.664\n",
       "latency_99th_percentile       116.459        24.179       21.6985\n",
       "latency_median                103.451       16.1085       13.9563\n",
       "latency_min                   76.3261       8.54301       8.63504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_ds = pd.DataFrame()\n",
    "\n",
    "col_name = lambda boption: f'trt_{boption[\"precision\"]}_{boption[\"batch_size\"]}'\n",
    "\n",
    "for boption in blist:\n",
    "    res, it = trt_predict_benchmark(**boption)\n",
    "    iter_ds = pd.concat([iter_ds, pd.DataFrame(it, columns=[col_name(boption)])], axis=1)\n",
    "    results = pd.concat([results, res], axis=1)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
