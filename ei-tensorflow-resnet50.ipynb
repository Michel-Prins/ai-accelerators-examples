{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 sync s3://imagenet-dataset-us-west-2/imagenet-data/tfrecords/validation/ /home/ubuntu/datasets/\n",
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"ei_client_version\": \"1.7.0\",\n",
      "  \"time\": \"Sat Sep 19 07:40:14 2020\",\n",
      "  \"attached_accelerators\": 2,\n",
      "  \"devices\": [\n",
      "    {\n",
      "      \"ordinal\": 0,\n",
      "      \"type\": \"eia2.large\",\n",
      "      \"id\": \"eia-63a6cf28f02841469c58055bff078a95\",\n",
      "      \"status\": \"healthy\"\n",
      "    },\n",
      "    {\n",
      "      \"ordinal\": 1,\n",
      "      \"type\": \"eia2.xlarge\",\n",
      "      \"id\": \"eia-ef9561df7dd74b308ecefbd8b362ca69\",\n",
      "      \"status\": \"healthy\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.contrib.ei.python.keras.ei_keras import EIKerasModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "!/opt/amazon/ei/ei_tools/bin/ei describe-accelerators --json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export SavedModel\n",
    "# saved_model_dir = 'resnet50_saved_model_fp32'\n",
    "# shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "# keras.backend.set_learning_phase(0)\n",
    "# model = ResNet50(weights='imagenet')\n",
    "# tf.saved_model.simple_save(session = keras.backend.get_session(),\n",
    "#                            export_dir = saved_model_dir,\n",
    "#                            inputs = {'input': model.inputs[0]},\n",
    "#                            outputs = {'output': model.outputs[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    [image,] = tf.py_function(preprocess_input, [image], [tf.float32])\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=8)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ei_predict_benchmark(model_type='ei', user_batch_size=1, use_cache=True, warm_up=10):\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    display_threshold = 0\n",
    "    warm_up = 10\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if model_type == 'ei':\n",
    "            mdl = EIKerasModel(ResNet50(weights='imagenet'), accelerator_id=1)\n",
    "        else:\n",
    "            mdl = ResNet50(weights='imagenet')\n",
    "            \n",
    "        if use_cache:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "\n",
    "        try:\n",
    "            sess.run(ds_init_op)\n",
    "            counter = 0\n",
    "\n",
    "            while True:\n",
    "                (validation_ds,label,_) = sess.run(ds_next)\n",
    "                if counter == 0:\n",
    "                    for i in range(warm_up):\n",
    "                        _ = mdl.predict(validation_ds);                    \n",
    "\n",
    "                start_time = time.time()\n",
    "                ei_results = mdl.predict(validation_ds);\n",
    "                iter_times.append(time.time() - start_time)\n",
    "\n",
    "                actual_labels.extend(l for k in label for l in k)\n",
    "                pred_labels.extend(list(np.argmax(ei_results, axis=1)))\n",
    "\n",
    "                if (counter)*user_batch_size >= display_threshold:\n",
    "                    print(f'Images {(counter)*user_batch_size}/50000. Average i/s {np.mean(user_batch_size/np.array(iter_times))}')\n",
    "                    display_threshold+=500\n",
    "\n",
    "                counter+=1\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['model']                   = [model_type]\n",
    "    results['accuracy']                = [acc_inf1]\n",
    "    results['prediction_time']         = [np.sum(iter_times)]\n",
    "    results['images_per_sec_mean']     = [np.mean(user_batch_size/np.array(iter_times))]\n",
    "    results['latency_per_thread_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results['latency_per_thread_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results['latency_per_thread_median']          = [np.median(iter_times) * 1000]\n",
    "    results['latency_per_thread_min']             = [np.min(iter_times) * 1000]\n",
    "    \n",
    "    display(results)\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-ba09100713e5>:10: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/ei/python/keras/ei_keras.py:158: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/ei/python/keras/ei_keras.py:158: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /tmp/tmpd6xam1sm/1/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /tmp/tmpd6xam1sm/1/saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/ei/python/keras/ei_keras.py:170: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/contrib/ei/python/keras/ei_keras.py:170: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpd6xam1sm/1/variables/variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/tmpd6xam1sm/1/variables/variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images 0/50000. Average i/s 170.343332913454\n",
      "Images 512/50000. Average i/s 169.37134483619406\n",
      "Images 1024/50000. Average i/s 169.48190616058457\n",
      "Images 1536/50000. Average i/s 169.45825076668805\n",
      "Images 2048/50000. Average i/s 169.41535395632232\n",
      "Images 2560/50000. Average i/s 170.1367773102819\n",
      "Images 3072/50000. Average i/s 170.33963741460698\n",
      "Images 3584/50000. Average i/s 170.48250189775416\n",
      "Images 4096/50000. Average i/s 170.55620783505245\n",
      "Images 4608/50000. Average i/s 170.48099711555795\n",
      "Images 5120/50000. Average i/s 170.46558918894445\n",
      "Images 5504/50000. Average i/s 170.40946254330353\n",
      "Images 6016/50000. Average i/s 170.33419953740122\n",
      "Images 6528/50000. Average i/s 170.39716505386428\n",
      "Images 7040/50000. Average i/s 170.57583140066703\n",
      "Images 7552/50000. Average i/s 170.96684764845335\n",
      "Images 8064/50000. Average i/s 171.22198539201256\n",
      "Images 8576/50000. Average i/s 171.42777154384743\n",
      "Images 9088/50000. Average i/s 171.56753051207332\n",
      "Images 9600/50000. Average i/s 171.7707588823742\n",
      "Images 10112/50000. Average i/s 171.94662978415892\n",
      "Images 10624/50000. Average i/s 172.0747326346686\n",
      "Images 11008/50000. Average i/s 172.13051747488785\n",
      "Images 11520/50000. Average i/s 172.18034032133014\n",
      "Images 12032/50000. Average i/s 172.24057418718579\n",
      "Images 12544/50000. Average i/s 172.30727106653595\n",
      "Images 13056/50000. Average i/s 172.330252729483\n",
      "Images 13568/50000. Average i/s 172.33534704855126\n",
      "Images 14080/50000. Average i/s 172.35475311034503\n",
      "Images 14592/50000. Average i/s 172.3985425865964\n",
      "Images 15104/50000. Average i/s 172.42801139168984\n",
      "Images 15616/50000. Average i/s 172.45344377020714\n",
      "Images 16000/50000. Average i/s 172.4428268437313\n",
      "Images 16512/50000. Average i/s 172.43466459129917\n",
      "Images 17024/50000. Average i/s 172.41937338792118\n",
      "Images 17536/50000. Average i/s 172.39240607355072\n",
      "Images 18048/50000. Average i/s 172.40342646213924\n",
      "Images 18560/50000. Average i/s 172.37141267795346\n",
      "Images 19072/50000. Average i/s 172.3789621560648\n",
      "Images 19584/50000. Average i/s 172.3462944136039\n",
      "Images 20096/50000. Average i/s 172.31914452400997\n",
      "Images 20608/50000. Average i/s 172.3176809857087\n",
      "Images 21120/50000. Average i/s 172.30634234822963\n",
      "Images 21504/50000. Average i/s 172.28559660995663\n",
      "Images 22016/50000. Average i/s 172.28228398055063\n",
      "Images 22528/50000. Average i/s 172.23203920638556\n",
      "Images 23040/50000. Average i/s 172.2037077533406\n",
      "Images 23552/50000. Average i/s 172.19105119201626\n",
      "Images 24064/50000. Average i/s 172.1625815392241\n",
      "Images 24576/50000. Average i/s 172.12887914063484\n",
      "Images 25088/50000. Average i/s 172.0997125388263\n",
      "Images 25600/50000. Average i/s 172.084888677355\n",
      "Images 26112/50000. Average i/s 172.07912185652125\n",
      "Images 26624/50000. Average i/s 172.07129081809666\n",
      "Images 27008/50000. Average i/s 172.06963718357576\n",
      "Images 27520/50000. Average i/s 172.066863077223\n",
      "Images 28032/50000. Average i/s 172.05535368703553\n",
      "Images 28544/50000. Average i/s 172.03960139091083\n",
      "Images 29056/50000. Average i/s 172.04405706724924\n",
      "Images 29568/50000. Average i/s 172.04654407507576\n",
      "Images 30080/50000. Average i/s 172.03824430177949\n",
      "Images 30592/50000. Average i/s 172.02430953645538\n",
      "Images 31104/50000. Average i/s 172.03546358081977\n",
      "Images 31616/50000. Average i/s 172.04559464659948\n",
      "Images 32000/50000. Average i/s 172.03829420115306\n",
      "Images 32512/50000. Average i/s 172.01898163142198\n",
      "Images 33024/50000. Average i/s 172.00156157354144\n",
      "Images 33536/50000. Average i/s 171.98808374087076\n",
      "Images 34048/50000. Average i/s 171.97498116435867\n",
      "Images 34560/50000. Average i/s 171.95146238543902\n",
      "Images 35072/50000. Average i/s 171.9409965137285\n",
      "Images 35584/50000. Average i/s 171.92297961561496\n",
      "Images 36096/50000. Average i/s 171.90831844351956\n",
      "Images 36608/50000. Average i/s 171.8879774862438\n",
      "Images 37120/50000. Average i/s 171.87386181118444\n",
      "Images 37504/50000. Average i/s 171.8668965898254\n",
      "Images 38016/50000. Average i/s 171.8564100951066\n",
      "Images 38528/50000. Average i/s 171.85169223159173\n",
      "Images 39040/50000. Average i/s 171.83887829570423\n",
      "Images 39552/50000. Average i/s 171.8238269749945\n",
      "Images 40064/50000. Average i/s 171.82301723452042\n",
      "Images 40576/50000. Average i/s 171.8195390814936\n",
      "Images 41088/50000. Average i/s 171.8090978515529\n",
      "Images 41600/50000. Average i/s 171.80682773171486\n",
      "Images 42112/50000. Average i/s 171.8140236095299\n",
      "Images 42624/50000. Average i/s 171.81134241041886\n",
      "Images 43008/50000. Average i/s 171.81110037885446\n",
      "Images 43520/50000. Average i/s 171.80445708325058\n",
      "Images 44032/50000. Average i/s 171.82006570002423\n",
      "Images 44544/50000. Average i/s 171.82041182229113\n",
      "Images 45056/50000. Average i/s 171.82685747496825\n",
      "Images 45568/50000. Average i/s 171.82472223861956\n",
      "Images 46080/50000. Average i/s 171.81973158665846\n",
      "Images 46592/50000. Average i/s 171.81866942253183\n",
      "Images 47104/50000. Average i/s 171.8206363357862\n",
      "Images 47616/50000. Average i/s 171.77696812365207\n",
      "Images 48000/50000. Average i/s 171.76983216147943\n",
      "Images 48512/50000. Average i/s 171.75691106420072\n",
      "Images 49024/50000. Average i/s 171.75679728455688\n",
      "Images 49536/50000. Average i/s 171.74282587864147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>latency_per_thread_99th_percentile</th>\n",
       "      <th>latency_per_thread_mean</th>\n",
       "      <th>latency_per_thread_median</th>\n",
       "      <th>latency_per_thread_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ei</td>\n",
       "      <td>0.74844</td>\n",
       "      <td>291.608116</td>\n",
       "      <td>171.668858</td>\n",
       "      <td>764.994621</td>\n",
       "      <td>745.800808</td>\n",
       "      <td>745.255709</td>\n",
       "      <td>722.103834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  accuracy  prediction_time  images_per_sec_mean  \\\n",
       "0    ei   0.74844       291.608116           171.668858   \n",
       "\n",
       "   latency_per_thread_99th_percentile  latency_per_thread_mean  \\\n",
       "0                          764.994621               745.800808   \n",
       "\n",
       "   latency_per_thread_median  latency_per_thread_min  \n",
       "0                 745.255709              722.103834  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "results = ei_predict_benchmark(model_type='ei', user_batch_size = batch_size, \n",
    "                                                 use_cache=False,\n",
    "                                                 warm_up=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.ei.python.predictor.ei_predictor import EIPredictor\n",
    "def ei_predict_benchmark_saved_model(model_dir='resnet50_saved_model_fp16',user_batch_size=1, use_cache=True, warm_up=10):\n",
    "    \n",
    "    eia_predictor = EIPredictor(model_dir,accelerator_id=1)\n",
    "            \n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    display_threshold = 0\n",
    "    warm_up = 10\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if use_cache:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "\n",
    "        try:\n",
    "            sess.run(ds_init_op)\n",
    "            counter = 0\n",
    "            ipname = list(eia_predictor.feed_tensors.keys())[0]\n",
    "            resname = list(eia_predictor.fetch_tensors.keys())[0]\n",
    "            \n",
    "            while True:\n",
    "                (validation_ds,label,_) = sess.run(ds_next)\n",
    "                model_feed_dict={ipname: validation_ds}\n",
    "                \n",
    "                if counter == 0:\n",
    "                    for i in range(warm_up):\n",
    "                        _ = eia_predictor(model_feed_dict);                    \n",
    "\n",
    "                start_time = time.time()\n",
    "                ei_results = eia_predictor(model_feed_dict);\n",
    "                iter_times.append(time.time() - start_time)\n",
    "\n",
    "                actual_labels.extend(l for k in label for l in k)\n",
    "                pred_labels.extend(list(np.argmax(ei_results[resname], axis=1)))\n",
    "\n",
    "                if (counter)*user_batch_size >= display_threshold:\n",
    "                    print(f'Images {(counter)*user_batch_size}/50000. Average i/s {np.mean(user_batch_size/np.array(iter_times))}')\n",
    "                    display_threshold+=500\n",
    "\n",
    "                counter+=1\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['model']                   = [model_dir]\n",
    "    results['accuracy']                = [acc_inf1]\n",
    "    results['prediction_time']         = [np.sum(iter_times)]\n",
    "    results['images_per_sec_mean']     = [np.mean(user_batch_size/np.array(iter_times))]\n",
    "    results['latency_per_thread_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results['latency_per_thread_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results['latency_per_thread_median']          = [np.median(iter_times) * 1000]\n",
    "    results['latency_per_thread_min']             = [np.min(iter_times) * 1000]\n",
    "    \n",
    "    display(results)\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using DEFAULT_SERVING_SIGNATURE_DEF_KEY .....\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images 0/50000. Average i/s 347.7458526032153\n",
      "Images 512/50000. Average i/s 303.43561842418654\n",
      "Images 1024/50000. Average i/s 298.616514579938\n",
      "Images 1536/50000. Average i/s 297.6800295711833\n",
      "Images 2048/50000. Average i/s 297.51473495602903\n",
      "Images 2560/50000. Average i/s 296.94056642074884\n",
      "Images 3072/50000. Average i/s 295.9987898650538\n",
      "Images 3584/50000. Average i/s 295.5611074867805\n",
      "Images 4096/50000. Average i/s 295.3565486885888\n",
      "Images 4608/50000. Average i/s 294.86760385902284\n",
      "Images 5120/50000. Average i/s 294.40674928995975\n",
      "Images 5504/50000. Average i/s 293.98356892121313\n",
      "Images 6016/50000. Average i/s 292.8397557759024\n",
      "Images 6528/50000. Average i/s 292.2506209877635\n",
      "Images 7040/50000. Average i/s 291.5824902531458\n",
      "Images 7552/50000. Average i/s 291.33338211728636\n",
      "Images 8064/50000. Average i/s 291.4911030120701\n",
      "Images 8576/50000. Average i/s 291.66555781835723\n",
      "Images 9088/50000. Average i/s 291.34363561631045\n",
      "Images 9600/50000. Average i/s 290.9210596504794\n",
      "Images 10112/50000. Average i/s 290.8592227651948\n",
      "Images 10624/50000. Average i/s 290.7364795029537\n",
      "Images 11008/50000. Average i/s 290.6341960192591\n",
      "Images 11520/50000. Average i/s 290.18110158731645\n",
      "Images 12032/50000. Average i/s 290.0111448548148\n",
      "Images 12544/50000. Average i/s 289.91036102327394\n",
      "Images 13056/50000. Average i/s 289.981666115538\n",
      "Images 13568/50000. Average i/s 289.9363141023686\n",
      "Images 14080/50000. Average i/s 290.06196745582895\n",
      "Images 14592/50000. Average i/s 290.13153975631593\n",
      "Images 15104/50000. Average i/s 290.1204565786563\n",
      "Images 15616/50000. Average i/s 290.09290193013106\n",
      "Images 16000/50000. Average i/s 290.0532082171507\n",
      "Images 16512/50000. Average i/s 289.8755305613082\n",
      "Images 17024/50000. Average i/s 289.782084612342\n",
      "Images 17536/50000. Average i/s 289.69143875662246\n",
      "Images 18048/50000. Average i/s 289.72472405093754\n",
      "Images 18560/50000. Average i/s 289.8312309510533\n",
      "Images 19072/50000. Average i/s 289.86553659736796\n",
      "Images 19584/50000. Average i/s 289.76988256049617\n",
      "Images 20096/50000. Average i/s 289.6592792157542\n",
      "Images 20608/50000. Average i/s 289.5686021639844\n",
      "Images 21120/50000. Average i/s 289.4134844750446\n",
      "Images 21504/50000. Average i/s 289.36677621203523\n",
      "Images 22016/50000. Average i/s 289.2481265951149\n",
      "Images 22528/50000. Average i/s 289.3066759878466\n",
      "Images 23040/50000. Average i/s 289.31424039288186\n",
      "Images 23552/50000. Average i/s 289.0499932267253\n",
      "Images 24064/50000. Average i/s 289.05747287962254\n",
      "Images 24576/50000. Average i/s 289.0104341223701\n",
      "Images 25088/50000. Average i/s 288.96180696254504\n",
      "Images 25600/50000. Average i/s 288.8687948366374\n",
      "Images 26112/50000. Average i/s 288.8806363173557\n",
      "Images 26624/50000. Average i/s 288.9891546165216\n",
      "Images 27008/50000. Average i/s 289.06096355268187\n",
      "Images 27520/50000. Average i/s 288.95732379463794\n",
      "Images 28032/50000. Average i/s 288.864632120822\n",
      "Images 28544/50000. Average i/s 288.70425429711906\n",
      "Images 29056/50000. Average i/s 288.65865572943045\n",
      "Images 29568/50000. Average i/s 288.6013429523446\n",
      "Images 30080/50000. Average i/s 288.62311810089517\n",
      "Images 30592/50000. Average i/s 288.6840906801785\n",
      "Images 31104/50000. Average i/s 288.7569930348718\n",
      "Images 31616/50000. Average i/s 288.71035358068576\n",
      "Images 32000/50000. Average i/s 288.68342460161756\n",
      "Images 32512/50000. Average i/s 288.63529178685553\n",
      "Images 33024/50000. Average i/s 288.63271221172056\n",
      "Images 33536/50000. Average i/s 288.5901944584937\n",
      "Images 34048/50000. Average i/s 288.60462338055413\n",
      "Images 34560/50000. Average i/s 288.5655845881988\n",
      "Images 35072/50000. Average i/s 288.4954819262448\n",
      "Images 35584/50000. Average i/s 288.5473004114444\n",
      "Images 36096/50000. Average i/s 288.585259156576\n",
      "Images 36608/50000. Average i/s 288.6311338716125\n",
      "Images 37120/50000. Average i/s 288.5167788081517\n",
      "Images 37504/50000. Average i/s 288.5136235686008\n",
      "Images 38016/50000. Average i/s 288.48389686653593\n",
      "Images 38528/50000. Average i/s 288.4969011751956\n",
      "Images 39040/50000. Average i/s 288.3568834010663\n",
      "Images 39552/50000. Average i/s 288.2753932777636\n",
      "Images 40064/50000. Average i/s 288.2052547159109\n",
      "Images 40576/50000. Average i/s 288.18954934025635\n",
      "Images 41088/50000. Average i/s 288.21061844430335\n",
      "Images 41600/50000. Average i/s 288.14904086779813\n",
      "Images 42112/50000. Average i/s 288.09989842619916\n",
      "Images 42624/50000. Average i/s 288.0368775802164\n",
      "Images 43008/50000. Average i/s 287.9949260777998\n",
      "Images 43520/50000. Average i/s 288.01972022654246\n",
      "Images 44032/50000. Average i/s 288.0717052206062\n",
      "Images 44544/50000. Average i/s 288.1121578846938\n",
      "Images 45056/50000. Average i/s 288.0543905873265\n",
      "Images 45568/50000. Average i/s 287.9844127064159\n",
      "Images 46080/50000. Average i/s 287.9813457632657\n",
      "Images 46592/50000. Average i/s 287.92114910289763\n",
      "Images 47104/50000. Average i/s 287.8748284197486\n",
      "Images 47616/50000. Average i/s 287.83173287086595\n",
      "Images 48000/50000. Average i/s 287.8108809113274\n",
      "Images 48512/50000. Average i/s 287.774518337562\n",
      "Images 49024/50000. Average i/s 287.7488198673393\n",
      "Images 49536/50000. Average i/s 287.80618808174927\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>latency_per_thread_99th_percentile</th>\n",
       "      <th>latency_per_thread_mean</th>\n",
       "      <th>latency_per_thread_median</th>\n",
       "      <th>latency_per_thread_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet50_saved_model_fp16</td>\n",
       "      <td>0.74862</td>\n",
       "      <td>173.697676</td>\n",
       "      <td>288.780592</td>\n",
       "      <td>475.766659</td>\n",
       "      <td>444.23958</td>\n",
       "      <td>442.209959</td>\n",
       "      <td>228.409052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model  accuracy  prediction_time  images_per_sec_mean  \\\n",
       "0  resnet50_saved_model_fp16   0.74862       173.697676           288.780592   \n",
       "\n",
       "   latency_per_thread_99th_percentile  latency_per_thread_mean  \\\n",
       "0                          475.766659                444.23958   \n",
       "\n",
       "   latency_per_thread_median  latency_per_thread_min  \n",
       "0                 442.209959              228.409052  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "results = ei_predict_benchmark_saved_model(model_dir='resnet50_saved_model_fp16',\n",
    "                                           user_batch_size = batch_size, \n",
    "                                           use_cache=False,\n",
    "                                           warm_up=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_amazonei_tensorflow_p36)",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
