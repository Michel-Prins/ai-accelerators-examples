{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Elastic Inference (EI) inference on Amazon EC2 CPU instance\n",
    "This example demonstrates Amazon Elastic Inference with Amazon EI enabled TensorFlow\n",
    "\n",
    "This example was tested on Amazon EC2 `c5.2xlarge` the following AWS Deep Learning AMI: \n",
    "`Deep Learning AMI (Ubuntu 18.04) Version 35.0`\n",
    "\n",
    "Run this notebook using the following conda environment:\n",
    "`amazonei_tensorflow2_p36`\n",
    "\n",
    "Prepare your imagenet validation TFRecord files using the following helper script:\n",
    "https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh\n",
    "\n",
    "Save it to `/home/ubuntu/datasets/` or update the dataset location in the `get_dataset()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from ei_for_tf.python.predictor.ei_predictor import EIPredictor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/29931\n",
    "temp = tf.zeros([8, 224, 224, 3])\n",
    "_ = tf.keras.applications.resnet50.preprocess_input(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      " {\n",
      "  \"acceleratorHealth\": {\n",
      "   \"status\": \"Ok\"\n",
      "  },\n",
      "  \"acceleratorType\": \"eia2.large\",\n",
      "  \"acceleratorId\": \"eia-63a6cf28f02841469c58055bff078a95\",\n",
      "  \"availabilityZone\": \"us-west-2a\",\n",
      "  \"attachedResource\": \"arn:aws:ec2:us-west-2:453691756499:instance/i-00487fc33ad7ef5eb\"\n",
      " },\n",
      " {\n",
      "  \"acceleratorHealth\": {\n",
      "   \"status\": \"Ok\"\n",
      "  },\n",
      "  \"acceleratorType\": \"eia2.xlarge\",\n",
      "  \"acceleratorId\": \"eia-ef9561df7dd74b308ecefbd8b362ca69\",\n",
      "  \"availabilityZone\": \"us-west-2a\",\n",
      "  \"attachedResource\": \"arn:aws:ec2:us-west-2:453691756499:instance/i-00487fc33ad7ef5eb\"\n",
      " }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "batch_size = 8\n",
    "\n",
    "ei_client = boto3.client('elastic-inference')\n",
    "print(json.dumps(ei_client.describe_accelerators()['acceleratorSet'], indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_save_resnet50_model(saved_model_dir = 'resnet50_saved_model'):\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "    model.save(saved_model_dir, include_optimizer=False, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_dir = 'resnet50_saved_model' \n",
    "# load_save_resnet50_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for CPU Keras, batch size: 8\n",
      "=======================================================\n",
      "\n",
      "Images 5000/50000. Average i/s 26.555694032421247\n",
      "Images 10000/50000. Average i/s 26.676666543597392\n",
      "Images 15000/50000. Average i/s 26.77406612095138\n",
      "Images 20000/50000. Average i/s 26.822275491462182\n",
      "Images 25000/50000. Average i/s 26.847471484622154\n",
      "Images 30000/50000. Average i/s 26.859330729648033\n",
      "Images 35000/50000. Average i/s 26.865594015573578\n",
      "Images 40000/50000. Average i/s 26.873174015987328\n",
      "Images 45000/50000. Average i/s 26.91567530151017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>accelerator</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keras_cpu_8</th>\n",
       "      <td>c5.2xlarge</td>\n",
       "      <td>NA</td>\n",
       "      <td>8</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>1860.75</td>\n",
       "      <td>1864.85</td>\n",
       "      <td>26.8839</td>\n",
       "      <td>0.502054</td>\n",
       "      <td>297.721</td>\n",
       "      <td>330.937</td>\n",
       "      <td>296.569</td>\n",
       "      <td>286.248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            instance_type accelerator user_batch_size accuracy  \\\n",
       "keras_cpu_8    c5.2xlarge          NA               8  0.74956   \n",
       "\n",
       "            prediction_time wall_time images_per_sec_mean images_per_sec_std  \\\n",
       "keras_cpu_8         1860.75   1864.85             26.8839           0.502054   \n",
       "\n",
       "            latency_mean latency_99th_percentile latency_median latency_min  \n",
       "keras_cpu_8      297.721                 330.937        296.569     286.248  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('\\n=======================================================')\n",
    "print(f'Benchmark results for CPU Keras, batch size: {batch_size}')\n",
    "print('=======================================================\\n')\n",
    "\n",
    "model = tf.keras.models.load_model(saved_model_dir)\n",
    "display_every = 5000\n",
    "display_threshold = display_every\n",
    "\n",
    "pred_labels = []\n",
    "actual_labels = []\n",
    "iter_times = []\n",
    "\n",
    "# Get the tf.data.TFRecordDataset object for the ImageNet2012 validation dataset\n",
    "dataset = get_dataset(batch_size)  \n",
    "\n",
    "walltime_start = time.time()\n",
    "for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "    start_time = time.time()\n",
    "    pred_prob_keras = model(validation_ds)\n",
    "    iter_times.append(time.time() - start_time)\n",
    "    \n",
    "    actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "    pred_labels.extend(list(np.argmax(pred_prob_keras, axis=1)))\n",
    "    \n",
    "    if i*batch_size >= display_threshold:\n",
    "        print(f'Images {i*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "        display_threshold+=display_every\n",
    "\n",
    "iter_times = np.array(iter_times)\n",
    "acc_keras_gpu = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "\n",
    "results = pd.DataFrame(columns = [f'keras_cpu_{batch_size}'])\n",
    "results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "results.loc['accelerator']             = ['NA']\n",
    "results.loc['user_batch_size']         = [batch_size]\n",
    "results.loc['accuracy']                = [acc_keras_gpu]\n",
    "results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "display(results.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ei_predict_benchmark(saved_model_dir, batch_size, accelerator_id):\n",
    "    \n",
    "    ei_size = ei_client.describe_accelerators()['acceleratorSet'][accelerator_id]['acceleratorType']\n",
    "\n",
    "    print('\\n=======================================================')\n",
    "    print(f'Benchmark results for EI: {ei_size}, batch size: {batch_size}')\n",
    "    print('=======================================================\\n')\n",
    "    \n",
    "    eia_model = EIPredictor(saved_model_dir, \n",
    "                                accelerator_id=1)\n",
    "\n",
    "    display_every = 5000\n",
    "    display_threshold = display_every\n",
    "\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    iter_times = []\n",
    "\n",
    "    # Get the tf.data.TFRecordDataset object for the ImageNet2012 validation dataset\n",
    "    dataset = get_dataset(batch_size)  \n",
    "\n",
    "    walltime_start = time.time()\n",
    "    ipname = list(eia_model.feed_tensors.keys())[0]\n",
    "    resname = list(eia_model.fetch_tensors.keys())[0]\n",
    "\n",
    "    for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "\n",
    "        model_feed_dict={'input_1': validation_ds.numpy()}\n",
    "        start_time = time.time()\n",
    "        pred_prob = eia_model(model_feed_dict)\n",
    "        iter_times.append(time.time() - start_time)\n",
    "\n",
    "        actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "        pred_labels.extend(list(np.argmax(pred_prob['probs'], axis=1)))\n",
    "\n",
    "        if i*batch_size >= display_threshold:\n",
    "            print(f'Images {i*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "            display_threshold+=display_every\n",
    "\n",
    "    iter_times = np.array(iter_times)\n",
    "    acc_keras_gpu = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    \n",
    "    results = pd.DataFrame(columns = [f'EI_{batch_size}_{ei_size}'])\n",
    "    results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "    results.loc['accelerator']             = [ei_size]\n",
    "    results.loc['user_batch_size']         = [batch_size]\n",
    "    results.loc['accuracy']                = [acc_keras_gpu]\n",
    "    results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "    results.loc['wall_time']               = [time.time() - walltime_start]\n",
    "    results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "    results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "    results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "    results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "    display(results.T)\n",
    "    \n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for EI: eia2.large, batch size: 8\n",
      "=======================================================\n",
      "\n",
      "Using DEFAULT_SERVING_SIGNATURE_DEF_KEY .....\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/ei_for_tf/python/predictor/ei_predictor.py:168: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "Images 5000/50000. Average i/s 160.79150457173685\n",
      "Images 10000/50000. Average i/s 160.57224536199263\n",
      "Images 15000/50000. Average i/s 160.17887928377442\n",
      "Images 20000/50000. Average i/s 159.55135762825725\n",
      "Images 25000/50000. Average i/s 159.05273547195634\n",
      "Images 30000/50000. Average i/s 158.55027160196224\n",
      "Images 35000/50000. Average i/s 158.2158252593362\n",
      "Images 40000/50000. Average i/s 157.88468338480075\n",
      "Images 45000/50000. Average i/s 157.15614275808505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>accelerator</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>wall_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EI_8_eia2.large</th>\n",
       "      <td>c5.2xlarge</td>\n",
       "      <td>eia2.large</td>\n",
       "      <td>8</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>321.635</td>\n",
       "      <td>331.082</td>\n",
       "      <td>157.271</td>\n",
       "      <td>5.04556</td>\n",
       "      <td>51.4616</td>\n",
       "      <td>55.3734</td>\n",
       "      <td>50.7524</td>\n",
       "      <td>47.5709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                instance_type accelerator user_batch_size accuracy  \\\n",
       "EI_8_eia2.large    c5.2xlarge  eia2.large               8  0.74956   \n",
       "\n",
       "                prediction_time wall_time images_per_sec_mean  \\\n",
       "EI_8_eia2.large         321.635   331.082             157.271   \n",
       "\n",
       "                images_per_sec_std latency_mean latency_99th_percentile  \\\n",
       "EI_8_eia2.large            5.04556      51.4616                 55.3734   \n",
       "\n",
       "                latency_median latency_min  \n",
       "EI_8_eia2.large        50.7524     47.5709  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keras_cpu_8</th>\n",
       "      <th>EI_8_eia2.large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_type</th>\n",
       "      <td>c5.2xlarge</td>\n",
       "      <td>c5.2xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accelerator</th>\n",
       "      <td>NA</td>\n",
       "      <td>eia2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.74956</td>\n",
       "      <td>0.74956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>1860.75</td>\n",
       "      <td>321.635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wall_time</th>\n",
       "      <td>1864.85</td>\n",
       "      <td>331.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>26.8839</td>\n",
       "      <td>157.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>0.502054</td>\n",
       "      <td>5.04556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>297.721</td>\n",
       "      <td>51.4616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>330.937</td>\n",
       "      <td>55.3734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>296.569</td>\n",
       "      <td>50.7524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>286.248</td>\n",
       "      <td>47.5709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        keras_cpu_8 EI_8_eia2.large\n",
       "instance_type            c5.2xlarge      c5.2xlarge\n",
       "accelerator                      NA      eia2.large\n",
       "user_batch_size                   8               8\n",
       "accuracy                    0.74956         0.74956\n",
       "prediction_time             1860.75         321.635\n",
       "wall_time                   1864.85         331.082\n",
       "images_per_sec_mean         26.8839         157.271\n",
       "images_per_sec_std         0.502054         5.04556\n",
       "latency_mean                297.721         51.4616\n",
       "latency_99th_percentile     330.937         55.3734\n",
       "latency_median              296.569         50.7524\n",
       "latency_min                 286.248         47.5709"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ei_options = [{'ei_acc_id': 0}]\n",
    "\n",
    "iter_ds = pd.DataFrame()\n",
    "if results is None:\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "col_name = lambda ei_acc_id: f'ei_{ei_client.describe_accelerators()[\"acceleratorSet\"][ei_acc_id][\"acceleratorType\"]}_batch_size_{batch_size}'\n",
    "\n",
    "    \n",
    "for opt in ei_options:\n",
    "    ei_acc_id = opt[\"ei_acc_id\"]\n",
    "    res, iter_times = ei_predict_benchmark(saved_model_dir, batch_size, ei_acc_id)\n",
    "    \n",
    "    iter_ds = pd.concat([iter_ds, pd.DataFrame(iter_times, columns=[col_name(ei_acc_id)])], axis=1)\n",
    "    results = pd.concat([results, res], axis=1)\n",
    "    \n",
    "display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_amazonei_tensorflow2_p36)",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
