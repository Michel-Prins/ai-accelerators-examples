{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neuron workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 sync s3://imagenet-dataset-us-west-2/imagenet-data/tfrecords/validation/ /home/ubuntu/datasets/\n",
    "# !pip install matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/aws/neuron/bin/neuron-cli reset\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.neuron as tfn\n",
    "import tensorflow.compat.v1.keras as keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from concurrent import futures\n",
    "from itertools import compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50 FP32 saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From <ipython-input-2-cc6f128953d9>:10: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_saved_model/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# Export SavedModel\n",
    "saved_model_dir = 'resnet50_saved_model'\n",
    "shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "\n",
    "keras.backend.set_learning_phase(0)\n",
    "model = ResNet50(weights='imagenet')\n",
    "tf.saved_model.simple_save(session = keras.backend.get_session(),\n",
    "                           export_dir = saved_model_dir,\n",
    "                           inputs = {'input_1:0': model.inputs[0]},\n",
    "                           outputs = {'probs/Softmax:0': model.outputs[0]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile models with different batch sizes and cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_inf1_model(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'resnet50_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "\n",
    "    compiler_args = ['--verbose','1', '--num-neuroncores', str(num_cores)]\n",
    "    if use_static_weights:\n",
    "        compiler_args.append('--static-weights')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_res = tfn.saved_model.compile(model_dir = saved_model_dir,\n",
    "                            model_feed_dict={'input_1:0': example_input},\n",
    "                            new_model_dir = inf1_compiled_model_dir,\n",
    "                            dynamic_batch_size=True,\n",
    "                            compiler_workdir=f'./compiler-workdir/{inf1_compiled_model_dir}',\n",
    "                            compiler_args = compiler_args)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "    perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "    if perc_on_inf > 50:\n",
    "        compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark sweep combinations:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'batch_size': 1, 'num_cores': 1},\n",
       " {'batch_size': 1, 'num_cores': 4},\n",
       " {'batch_size': 1, 'num_cores': 16, 'use_static_weights': True},\n",
       " {'batch_size': 2, 'num_cores': 1},\n",
       " {'batch_size': 2, 'num_cores': 4},\n",
       " {'batch_size': 2, 'num_cores': 16, 'use_static_weights': True},\n",
       " {'batch_size': 3, 'num_cores': 1},\n",
       " {'batch_size': 3, 'num_cores': 4},\n",
       " {'batch_size': 3, 'num_cores': 16, 'use_static_weights': True},\n",
       " {'batch_size': 4, 'num_cores': 1},\n",
       " {'batch_size': 4, 'num_cores': 4},\n",
       " {'batch_size': 4, 'num_cores': 16, 'use_static_weights': True},\n",
       " {'batch_size': 5, 'num_cores': 1},\n",
       " {'batch_size': 5, 'num_cores': 4},\n",
       " {'batch_size': 5, 'num_cores': 16, 'use_static_weights': True}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "compile_options = {\n",
    "    'batch_size': [1, 2, 3, 4, 5],\n",
    "    'num_cores': [1, 4, 16]\n",
    "}\n",
    "\n",
    "cname, cval = zip(*compile_options.items())\n",
    "compile_opt_list = [dict(zip(cname, h)) for h in itertools.product(*cval)]\n",
    "\n",
    "print('Benchmark sweep combinations:')\n",
    "\n",
    "for i, arg in enumerate(compile_opt_list):\n",
    "    if arg['num_cores'] == 16:\n",
    "        compile_opt_list[i] = {**arg, 'use_static_weights': True}\n",
    "\n",
    "display(compile_opt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------batch size: 1, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 556\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 554\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "Compile time: 99.41635584831238\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.9964028776978417}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 1, num cores: 4----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 556\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 554\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4\n",
      "Compile time: 100.78115224838257\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_4\n",
      "{'OnNeuronRatio': 0.9964028776978417}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 1, num cores: 16----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 556\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 554\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_16/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_16\n",
      "Compile time: 117.30518221855164\n",
      "resnet50_inf1_saved_models/resnet50_batch_1_inf1_cores_16\n",
      "{'OnNeuronRatio': 0.9964028776978417}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 2, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[2, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 1'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 07:48:26 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: \n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: \n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[2, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 1\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: \n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: \n",
      "10/18/2020 07:48:26 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 07:48:28 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 122.39245676994324\n",
      "resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 2, num cores: 4----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 556\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 554\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_4/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_4\n",
      "Compile time: 223.24913430213928\n",
      "resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_4\n",
      "{'OnNeuronRatio': 0.9964028776978417}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 2, num cores: 16----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 556\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 554\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_16/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_16\n",
      "Compile time: 165.41489911079407\n",
      "resnet50_inf1_saved_models/resnet50_batch_2_inf1_cores_16\n",
      "{'OnNeuronRatio': 0.9964028776978417}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 3, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[3, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 1'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 07:57:15 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: \n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: \n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[3, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 1\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: \n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: \n",
      "10/18/2020 07:57:15 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 07:57:16 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_1/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_1 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 139.40126490592957\n",
      "resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 3, num cores: 4----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[3, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 4'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 08:00:23 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[3, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 4\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:00:23 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 08:00:24 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_4/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_4 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 188.68506407737732\n",
      "resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_4\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 3, num cores: 16----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 556\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 554\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_16/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_16\n",
      "Compile time: 229.30698418617249\n",
      "resnet50_inf1_saved_models/resnet50_batch_3_inf1_cores_16\n",
      "{'OnNeuronRatio': 0.9964028776978417}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 4, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[4, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 1'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 08:08:25 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[4, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 1\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:08:25 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 08:08:26 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 252.37601780891418\n",
      "resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 4, num cores: 4----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[4, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 4'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 08:12:08 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[4, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 4\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:12:08 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 08:12:09 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_4/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_4 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 223.02034378051758\n",
      "resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_4\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 4, num cores: 16----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[4, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 16 --static-weights'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 08:15:10 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[4, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 16 --static-weights\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:15:10 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 08:15:11 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_16/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_16 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 181.94180941581726\n",
      "resnet50_inf1_saved_models/resnet50_batch_4_inf1_cores_16\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 5, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[5, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 1'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 08:21:31 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[5, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 1\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:21:31 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 08:21:32 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 380.62819385528564\n",
      "resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 5, num cores: 4----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[5, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 4'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 08:27:55 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_4/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[5, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 4\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:27:55 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 08:27:56 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_4/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_4 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 384.35404753685\n",
      "resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_4\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n",
      "-----------batch size: 5, num cores: 16----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "WARNING:tensorflow:Failed to fuse subgraph neuron_op_d6f098c01c780733 with '/home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neff --io-config \"{\\\"inputs\\\": {\\\"input_10/_0:0\\\": [[5, 224, 224, 3], \\\"float32\\\"]}, \\\"outputs\\\": [\\\"probs/Softmax:0\\\"]}\" --verbose 1 --num-neuroncores 16 --static-weights'\n",
      "WARNING:tensorflow:neuron-cc error message:\n",
      "WARNING:tensorflow:10/18/2020 08:31:07 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]:  An Internal Compiler Error has occurred\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: ***************************************************************\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: Error message:  Scheduler Failure!\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: Error class:    AssertionError\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: Error location: job.Scheduler.3\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: Command line:   /home/ubuntu/anaconda3/envs/aws_neuron_tensorflow_p36/bin/neuron-cc compile /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.pb --framework TENSORFLOW --pipeline compile SaveTemps --output /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_16/neuron_op_d6f098c01c780733/graph_def.neff --io-config '{\"inputs\": {\"input_10/_0:0\": [[5, 224, 224, 3], \"float32\"]}, \"outputs\": [\"probs/Softmax:0\"]}' --verbose 1 --num-neuroncores 16 --static-weights\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: Internal details:\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]:   File \"neuroncc/driver/Job.py\", line 234, in neuroncc.driver.Job.runSingleInputFn\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]:   File \"neuroncc/driver/jobs/Scheduler.py\", line 68, in neuroncc.driver.jobs.Scheduler.Scheduler.runSingleInput\n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: \n",
      "10/18/2020 08:31:07 AM ERROR [neuron-cc]: Version information:\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   Neuron Compiler version 1.0.18001.0+0.5312e6a21\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   \n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   HWM version 1.0.1592.0-0\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   NEFF version 1.0\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   TVM version 1.0.2831.0+0\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   NumPy version 1.19.1\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   MXNet not available\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   TF version 1.15.3\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]:   ONNX not available\n",
      "10/18/2020 08:31:08 AM ERROR [neuron-cc]: \n",
      "\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 555\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 0\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_16/saved_model.pb\n",
      "WARNING:tensorflow:Converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_16 but no operator will be running on AWS machine learning accelerators. This is probably not what you want. Please refer to https://github.com/aws/aws-neuron-sdk for current limitations of the AWS Neuron SDK. We are actively improving (and hiring)!\n",
      "Compile time: 191.9899458885193\n",
      "resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_16\n",
      "{'OnNeuronRatio': 0.0}\n",
      "----------- Done! ----------- \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compiled status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 1, 'num_cores': 1}</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 1, 'num_cores': 4}</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 1, 'num_cores': 16, 'use_static_weights': True}</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 2, 'num_cores': 1}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 2, 'num_cores': 4}</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 2, 'num_cores': 16, 'use_static_weights': True}</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 3, 'num_cores': 1}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 3, 'num_cores': 4}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 3, 'num_cores': 16, 'use_static_weights': True}</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 4, 'num_cores': 1}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 4, 'num_cores': 4}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 4, 'num_cores': 16, 'use_static_weights': True}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 5, 'num_cores': 1}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 5, 'num_cores': 4}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'batch_size': 5, 'num_cores': 16, 'use_static_weights': True}</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Compiled status\n",
       "{'batch_size': 1, 'num_cores': 1}                             True\n",
       "{'batch_size': 1, 'num_cores': 4}                             True\n",
       "{'batch_size': 1, 'num_cores': 16, 'use_static_...            True\n",
       "{'batch_size': 2, 'num_cores': 1}                            False\n",
       "{'batch_size': 2, 'num_cores': 4}                             True\n",
       "{'batch_size': 2, 'num_cores': 16, 'use_static_...            True\n",
       "{'batch_size': 3, 'num_cores': 1}                            False\n",
       "{'batch_size': 3, 'num_cores': 4}                            False\n",
       "{'batch_size': 3, 'num_cores': 16, 'use_static_...            True\n",
       "{'batch_size': 4, 'num_cores': 1}                            False\n",
       "{'batch_size': 4, 'num_cores': 4}                            False\n",
       "{'batch_size': 4, 'num_cores': 16, 'use_static_...           False\n",
       "{'batch_size': 5, 'num_cores': 1}                            False\n",
       "{'batch_size': 5, 'num_cores': 4}                            False\n",
       "{'batch_size': 5, 'num_cores': 16, 'use_static_...           False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf1_model_dir = 'resnet50_inf1_saved_models'\n",
    "shutil.rmtree(inf1_model_dir, ignore_errors=True)\n",
    "\n",
    "df = pd.DataFrame(columns = ['Compiled status'])\n",
    "\n",
    "for opt in compile_opt_list:\n",
    "    compile_status = compile_inf1_model(saved_model_dir, inf1_model_dir, **opt)\n",
    "    df.loc[str(opt)] = compile_status\n",
    "    \n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------batch size: 5, num cores: 1----------\n",
      "Compiling...\n",
      "INFO:tensorflow:Restoring parameters from resnet50_saved_model/variables/variables\n",
      "INFO:tensorflow:Froze 320 variables.\n",
      "INFO:tensorflow:Converted 320 variables to const ops.\n",
      "INFO:tensorflow:fusing subgraph neuron_op_d6f098c01c780733 with neuron-cc; log file is at /home/ubuntu/examples/ai-accelerators-examples/compiler-workdir/resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1/neuron_op_d6f098c01c780733/graph_def.neuron-cc.log\n",
      "INFO:tensorflow:Number of operations in TensorFlow session: 4638\n",
      "INFO:tensorflow:Number of operations after tf.neuron optimizations: 556\n",
      "INFO:tensorflow:Number of operations placed on Neuron runtime: 554\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1/saved_model.pb\n",
      "INFO:tensorflow:Successfully converted resnet50_saved_model to resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1\n",
      "Compile time: 171.56691431999207\n",
      "resnet50_inf1_saved_models/resnet50_batch_5_inf1_cores_1\n",
      "{'OnNeuronRatio': 0.9964028776978417}\n",
      "----------- Done! ----------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compile_inf1_model_test(saved_model_dir, inf1_model_dir, batch_size=1, num_cores=1, use_static_weights=False):\n",
    "    print(f'-----------batch size: {batch_size}, num cores: {num_cores}----------')\n",
    "    print('Compiling...')\n",
    "    \n",
    "    compiled_model_dir = f'resnet50_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(inf1_model_dir, compiled_model_dir)\n",
    "    shutil.rmtree(inf1_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    example_input = np.zeros([batch_size,224,224,3], dtype='float32')\n",
    "\n",
    "#     compiler_args = ['--verbose','1', '--num-neuroncores', str(num_cores)]\n",
    "    compiler_args = ['--batching_en', '--rematerialization_en', '--spill_dis',\n",
    "                 '--sb_size', str((batch_size + 6)*10),\n",
    "                 '--enable-replication', 'True', '-O2',\n",
    "                 '--verbose','1', '--num-neuroncores', str(num_cores)]\n",
    "        \n",
    "    if use_static_weights:\n",
    "        compiler_args.append('--static-weights')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    compiled_res = tfn.saved_model.compile(model_dir = saved_model_dir,\n",
    "                            model_feed_dict={'input_1:0': example_input},\n",
    "                            new_model_dir = inf1_compiled_model_dir,\n",
    "                            dynamic_batch_size=True,\n",
    "                            compiler_workdir=f'./compiler-workdir/{inf1_compiled_model_dir}',\n",
    "                            compiler_args = compiler_args)\n",
    "    print(f'Compile time: {time.time() - start_time}')\n",
    "    \n",
    "    compile_success = False\n",
    "    perc_on_inf = compiled_res['OnNeuronRatio'] * 100\n",
    "    if perc_on_inf > 50:\n",
    "        compile_success = True\n",
    "            \n",
    "    print(inf1_compiled_model_dir)\n",
    "    print(compiled_res)\n",
    "    print('----------- Done! ----------- \\n')\n",
    "    \n",
    "    return compile_success\n",
    "\n",
    "inf1_model_dir = 'resnet50_inf1_saved_models'\n",
    "compile_status = compile_inf1_model_test(saved_model_dir, inf1_model_dir, \n",
    "                                    **{'batch_size': 5, 'num_cores': 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    [image,] = tf.py_function(preprocess_input, [image], [tf.float32])\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/home/ubuntu/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=8)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single threaded execution: Single core and multi-core pipeline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inf1_predict_benchmark_single_threaded(neuron_saved_model_name, user_batch_size, use_cache=True, warm_up=10):\n",
    "    print(f'Running model {neuron_saved_model_name}, user_batch_size: {user_batch_size}\\n')\n",
    "\n",
    "    model_inf1 = tf.contrib.predictor.from_saved_model(neuron_saved_model_name)\n",
    "\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    display_threshold = 0\n",
    "    warm_up = 10\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        if use_cache:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "\n",
    "        try:\n",
    "            sess.run(ds_init_op)\n",
    "            counter = 0\n",
    "            ipname = list(model_inf1.feed_tensors.keys())[0]\n",
    "            resname = list(model_inf1.fetch_tensors.keys())[0]\n",
    "\n",
    "            while True:\n",
    "                (validation_ds,label,_) = sess.run(ds_next)\n",
    "\n",
    "                model_feed_dict={ipname: validation_ds}\n",
    "\n",
    "                if counter == 0:\n",
    "                    for i in range(warm_up):\n",
    "                        _ = model_inf1(model_feed_dict);                    \n",
    "\n",
    "                start_time = time.time()\n",
    "                inf1_results = model_inf1(model_feed_dict);\n",
    "                iter_times.append(time.time() - start_time)\n",
    "\n",
    "                actual_labels.extend(l for k in label for l in k)\n",
    "                pred_labels.extend(list(np.argmax(inf1_results[resname], axis=1)))\n",
    "\n",
    "                if (counter+1)*user_batch_size >= display_threshold:\n",
    "                    print(f'Images {(counter+1)*user_batch_size}/50000. Average i/s {np.mean(user_batch_size/np.array(iter_times))}')\n",
    "                    display_threshold+=5000\n",
    "\n",
    "                counter+=1\n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            pass\n",
    "        \n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['model']                   = [f'{compiled_model_dir}_user_batch_{user_batch_size}_single_core']\n",
    "    results['accuracy']                = [acc_inf1]\n",
    "    results['prediction_time']         = [np.sum(iter_times)]\n",
    "    results['images_per_sec_mean']     = [np.mean(user_batch_size/np.array(iter_times))]\n",
    "    results['latency_per_thread_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results['latency_per_thread_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results['latency_per_thread_median']          = [np.median(iter_times) * 1000]\n",
    "    results['latency_per_thread_min']             = [np.min(iter_times) * 1000]\n",
    "    \n",
    "    display(results)\n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_cores = 1\n",
    "\n",
    "saved_model_dir = f'resnet50_saved_model_{compiled_model_precision}'\n",
    "parent_dir = 'resnet50_inf1_saved_models'\n",
    "\n",
    "compiled_model_dir = f'resnet50_{compiled_model_precision}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "inf1_compiled_model_dir = os.path.join(parent_dir, compiled_model_dir)\n",
    "\n",
    "print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "print(f'compiled_model_precision: {compiled_model_precision}')\n",
    "\n",
    "results, latency_per_thread = inf1_predict_benchmark_single_threaded_1(inf1_compiled_model_dir, \n",
    "                                                                     user_batch_size = batch_size*10, \n",
    "                                                                     use_cache=False, \n",
    "                                                                     warm_up=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-threaded execution\n",
    "### Benchmark: Measure using latency of first thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multi-process multi-core batched\n",
    "# def inf1_benchmark_latency_first_threads(neuron_saved_model_name, user_batch_size, num_model_copies, threads_per_model = 1, use_cache=True, warm_up=True):\n",
    "#     try:\n",
    "#         predictor_list = [tf.contrib.predictor.from_saved_model(neuron_saved_model_name) for _ in range(num_model_copies)]\n",
    "#     except Exception as e:\n",
    "#         print(str(e))\n",
    "\n",
    "#     predictor_list = predictor_list * threads_per_model\n",
    "#     inference_threads = len(predictor_list)\n",
    "        \n",
    "#     global latency_per_thread, counter, total_images_predicted, total_latency, total_throughput\n",
    "#     latency_per_thread = [[] for _ in range(inference_threads)]\n",
    "#     total_images_predicted = [0 for _ in range(inference_threads)]\n",
    "#     total_latency = [0 for _ in range(inference_threads)]\n",
    "#     total_throughput = []\n",
    "#     counter = 0\n",
    "    \n",
    "#     ipname = list(predictor_list[0].feed_tensors.keys())[0]\n",
    "#     resname = list(predictor_list[0].fetch_tensors.keys())[0]\n",
    "\n",
    "#     iter_times = []\n",
    "#     pred_labels = []\n",
    "#     actual_labels = []\n",
    "\n",
    "#     ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "#     ds_iter = ds.make_initializable_iterator()\n",
    "#     ds_next = ds_iter.get_next()\n",
    "#     ds_init_op = ds_iter.initializer\n",
    "    \n",
    "#     if use_cache:\n",
    "#         with tf.Session() as sess:\n",
    "#             sess.run(ds_init_op)\n",
    "#             print('\\nCaching dataset ...')\n",
    "#             start_time = time.time()\n",
    "#             try:\n",
    "#                 while True:\n",
    "#                     (validation_ds,label,_) = sess.run(ds_next)\n",
    "#             except tf.errors.OutOfRangeError:\n",
    "#                 pass\n",
    "#             print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "            \n",
    "#     ds_iter = ds.make_initializable_iterator()\n",
    "#     ds_next = ds_iter.get_next()\n",
    "#     ds_init_op = ds_iter.initializer\n",
    "    \n",
    "#     def inf1_predict(predictor, model_feed_dict, counter, inference_threads, thread_assignment, user_batch_size, warm_up):\n",
    "#         global latency_per_thread, total_images_predicted, total_latency\n",
    "#         if counter in range(inference_threads):\n",
    "#             if warm_up:\n",
    "#                 _ = predictor(model_feed_dict)\n",
    "       \n",
    "#         start_time = time.time()\n",
    "#         pred = predictor(model_feed_dict)\n",
    "#         latency = time.time() - start_time\n",
    "        \n",
    "#         latency_per_thread[thread_assignment].append(latency)\n",
    "#         total_images_predicted[thread_assignment] += user_batch_size\n",
    "#         total_latency[thread_assignment] += latency\n",
    "        \n",
    "#         return {'index':counter,'latency':latency, **pred}\n",
    "    \n",
    "#     def measure_throughput(user_batch_size):\n",
    "#         global counter, total_images_predicted, total_latency, total_throughput, throughput\n",
    "#         display_threshold = 0\n",
    "#         start_time = 0\n",
    "#         throughput = 0\n",
    "#         while counter >= 0:\n",
    "#             if total_latency[0] > 1.0:\n",
    "#                 throughput = sum(total_images_predicted)/total_latency[0]\n",
    "#                 total_throughput.append(throughput)\n",
    "#                 total_images_predicted = [0 for _ in range(len(total_images_predicted))]\n",
    "#                 total_latency = [0 for _ in range(len(total_latency))]\n",
    "#             if (counter)*user_batch_size >= display_threshold:\n",
    "#                 print(f'Images: {counter*user_batch_size}/50000. Average images/sec across threads: {throughput}')\n",
    "#                 display_threshold+=5000\n",
    "\n",
    "#     # submit each image to predictors in a round-robin fashion\n",
    "#     future_list = []\n",
    "#     with futures.ThreadPoolExecutor(max_workers=inference_threads + 1) as executor:\n",
    "#         executor.submit(measure_throughput, user_batch_size)\n",
    "#         inference_walltime = time.time()\n",
    "#         with tf.Session() as sess:\n",
    "#             try:\n",
    "#                 sess.run(ds_init_op)\n",
    "#                 while True:\n",
    "#                     (validation_ds,label,_) = sess.run(ds_next)\n",
    "#                     model_feed_dict={ipname: validation_ds}\n",
    "#                     actual_labels.extend(l for k in label for l in k)\n",
    "                    \n",
    "#                     thread_assignment = counter % len(predictor_list)\n",
    "#                     predictor = predictor_list[thread_assignment]\n",
    "#                     ex_results = executor.submit(inf1_predict, predictor, model_feed_dict, counter, inference_threads, thread_assignment, user_batch_size, warm_up)\n",
    "                    \n",
    "#                     future_list.append(ex_results)\n",
    "#                     counter+=1\n",
    "\n",
    "#             except tf.errors.OutOfRangeError:\n",
    "#                 counter = -1\n",
    "#                 pass\n",
    "\n",
    "#         pred_labels = []\n",
    "#         img_index = []\n",
    "#         iter_times_all_threads = []\n",
    "#         for f in future_list:\n",
    "#             res = f.result()\n",
    "#             img_index.append(res['index'])\n",
    "#             iter_times_all_threads.append(res['latency'])\n",
    "#             pred_labels.extend(np.argmax(res['probs/Softmax:0'], axis=1))\n",
    "#         inference_walltime = time.time() - inference_walltime\n",
    "        \n",
    "#     iter_times_all_threads = np.array(iter_times_all_threads)\n",
    "#     acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    \n",
    "#     results = pd.DataFrame()\n",
    "#     results['model']                              = [neuron_saved_model_name]\n",
    "#     results['instance_type']                      = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "#     results['user_batch_size']                    = [user_batch_size]\n",
    "#     results['num_model_copies']                   = [num_model_copies]\n",
    "#     results['threads_per_model']                  = [threads_per_model]\n",
    "#     results['accuracy']                           = [acc_inf1]\n",
    "#     results['prediction_time']                    = [np.sum(iter_times_all_threads)]\n",
    "#     results['images_per_sec_mean']                = [np.mean(total_throughput)]\n",
    "#     results['images_per_sec_per_thread_mean']     = [np.mean(user_batch_size / iter_times_all_threads)]\n",
    "#     results['latency_per_thread_99th_percentile'] = [np.percentile(iter_times_all_threads, q=99, interpolation=\"lower\") * 1000]\n",
    "#     results['latency_per_thread_mean']            = [np.mean(iter_times_all_threads) * 1000]\n",
    "#     results['latency_per_thread_median']          = [np.median(iter_times_all_threads) * 1000]\n",
    "#     results['latency_per_thread_min']             = [np.min(iter_times_all_threads) * 1000]\n",
    "#     results['inference_walltime']                 = [inference_walltime]\n",
    "\n",
    "#     display(results)\n",
    "#     return results, latency_per_thread, iter_times_all_threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-threaded execution\n",
    "### Benchmark: Measure using max latency thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate images per 1 sec, Multi-process multi-core batched\n",
    "def inf1_benchmark_latency_max_threads(neuron_saved_model_name, user_batch_size, num_model_copies, threads_per_model = 1, use_cache=True, warm_up=True):\n",
    "    \n",
    "    try:\n",
    "        predictor_list = [tf.contrib.predictor.from_saved_model(neuron_saved_model_name) for _ in range(num_model_copies)]\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "    predictor_list = predictor_list * threads_per_model\n",
    "    inference_threads = len(predictor_list)\n",
    "        \n",
    "    global latency_per_thread, counter, total_images_predicted, total_latency, total_throughput\n",
    "    latency_per_thread = [[] for _ in range(inference_threads)]\n",
    "    total_images_predicted = [0 for _ in range(inference_threads)]\n",
    "    total_latency = [0 for _ in range(inference_threads)]\n",
    "    total_throughput = []\n",
    "    counter = 0\n",
    "    \n",
    "    ipname = list(predictor_list[0].feed_tensors.keys())[0]\n",
    "    resname = list(predictor_list[0].fetch_tensors.keys())[0]\n",
    "\n",
    "    iter_times = []\n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "\n",
    "    ds = get_dataset(user_batch_size, use_cache)\n",
    "\n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "    \n",
    "    if use_cache:\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(ds_init_op)\n",
    "            print('\\nCaching dataset ...')\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                pass\n",
    "            print(f'Caching finished: {time.time()-start_time} sec')  \n",
    "            \n",
    "    ds_iter = ds.make_initializable_iterator()\n",
    "    ds_next = ds_iter.get_next()\n",
    "    ds_init_op = ds_iter.initializer\n",
    "    \n",
    "    def inf1_predict(predictor, model_feed_dict, counter, inference_threads, thread_assignment, user_batch_size, warm_up):\n",
    "        global latency_per_thread, total_images_predicted, total_latency\n",
    "        if counter in range(inference_threads):\n",
    "            if warm_up:\n",
    "                _ = predictor(model_feed_dict)\n",
    "       \n",
    "        start_time = time.time()\n",
    "        pred = predictor(model_feed_dict)\n",
    "        latency = time.time() - start_time\n",
    "        \n",
    "        latency_per_thread[thread_assignment].append(latency)\n",
    "        total_images_predicted[thread_assignment] += user_batch_size\n",
    "        total_latency[thread_assignment] += latency\n",
    "        \n",
    "        return {'index':counter,'latency':latency, **pred}\n",
    "    \n",
    "    def measure_throughput(user_batch_size):\n",
    "        global counter, total_images_predicted, total_latency, total_throughput, throughput\n",
    "        display_threshold = 0\n",
    "        start_time = 0\n",
    "        throughput = 0\n",
    "        while counter >= 0:\n",
    "            if max(total_latency) -  start_time > 0.1:\n",
    "                throughput = 10*sum(total_images_predicted)/max(total_latency)\n",
    "                total_throughput.append(throughput)\n",
    "                start_time = 0\n",
    "                total_images_predicted = [0 for _ in range(len(total_images_predicted))]\n",
    "                total_latency = [0 for _ in range(len(total_latency))]\n",
    "            if (counter)*user_batch_size >= display_threshold:\n",
    "                print(f'Images: {counter*user_batch_size}/50000. Average images/sec across threads: {throughput}')\n",
    "                display_threshold+=5000\n",
    "\n",
    "    # submit each image to predictors in a round-robin fashion\n",
    "    future_list = []\n",
    "    with futures.ThreadPoolExecutor(max_workers=inference_threads + 1) as executor:\n",
    "        executor.submit(measure_throughput, user_batch_size)\n",
    "        with tf.Session() as sess:\n",
    "            try:\n",
    "                sess.run(ds_init_op)\n",
    "                while True:\n",
    "                    (validation_ds,label,_) = sess.run(ds_next)\n",
    "                    model_feed_dict={ipname: validation_ds}\n",
    "                    actual_labels.extend(l for k in label for l in k)\n",
    "                    \n",
    "                    thread_assignment = counter % len(predictor_list)\n",
    "                    predictor = predictor_list[thread_assignment]\n",
    "                    ex_results = executor.submit(inf1_predict, predictor, model_feed_dict, counter, inference_threads, thread_assignment, user_batch_size, warm_up)\n",
    "                    \n",
    "                    future_list.append(ex_results)\n",
    "                    counter+=1\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                counter = -1\n",
    "                pass\n",
    "\n",
    "        pred_labels = []\n",
    "        img_index = []\n",
    "        iter_times_all_threads = []\n",
    "        for f in future_list:\n",
    "            res = f.result()\n",
    "            img_index.append(res['index'])\n",
    "            iter_times_all_threads.append(res['latency'])\n",
    "            pred_labels.extend(np.argmax(res['probs/Softmax:0'], axis=1))\n",
    "    \n",
    "    iter_times_all_threads = np.array(iter_times_all_threads)\n",
    "    acc_inf1 = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['model']                              = [neuron_saved_model_name]\n",
    "    results['instance_type']                      = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "    results['user_batch_size']                    = [user_batch_size]\n",
    "    results['num_model_copies']                   = [num_model_copies]\n",
    "    results['threads_per_model']                  = [threads_per_model]\n",
    "    results['accuracy']                           = [acc_inf1]\n",
    "    results['prediction_time']                    = [np.sum(iter_times_all_threads)]\n",
    "    results['images_per_sec_mean']                = [np.mean(total_throughput)]\n",
    "    results['images_per_sec_per_thread_mean']     = [np.mean(user_batch_size / iter_times_all_threads)]\n",
    "    results['latency_per_thread_99th_percentile'] = [np.percentile(iter_times_all_threads, q=99, interpolation=\"lower\") * 1000]\n",
    "    results['latency_per_thread_mean']            = [np.mean(iter_times_all_threads) * 1000]\n",
    "    results['latency_per_thread_median']          = [np.median(iter_times_all_threads) * 1000]\n",
    "    results['latency_per_thread_min']             = [np.min(iter_times_all_threads) * 1000]\n",
    "    display(results)\n",
    "    return results, latency_per_thread, iter_times_all_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_inference_request(batch_size, compiled_num_cores, saved_model_precision, num_model_copies=0, threads_per_model=2):\n",
    "    avail_neuroncores_dict = {\n",
    "        'inf1.xlarge' : 4,\n",
    "        'inf1.2xlarge' : 4,\n",
    "        'inf1.6xlarge' : 16,\n",
    "        'inf1.24xlarge' : 64\n",
    "    }\n",
    "    instance_type = requests.get('http://169.254.169.254/latest/meta-data/instance-type').text\n",
    "    avail_num_cores = avail_neuroncores_dict.get(instance_type, 0)\n",
    "    \n",
    "    if not num_model_copies:\n",
    "        num_model_copies = avail_num_cores//compiled_num_cores\n",
    "    \n",
    "    user_batch_size = batch_size*10\n",
    "\n",
    "    parent_dir = 'resnet50_inf1_saved_models'\n",
    "    compiled_model_dir = f'resnet50_{saved_model_precision}_batch_{batch_size}_inf1_cores_{compiled_num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(parent_dir, compiled_model_dir)\n",
    "\n",
    "    print(f\"\"\"\n",
    "-> Compiled batch size: {batch_size}\n",
    "-> Compiled neuron cores: {compiled_num_cores}\n",
    "-> Saved model precision: {saved_model_precision}\n",
    "\n",
    "-> Available neuron cores: {avail_num_cores}\n",
    "-> Number of model copies that fits on {instance_type}: {num_model_copies}\n",
    "-> Number of CPU threads to feed each model: {threads_per_model}\n",
    "-> User batch size: {user_batch_size}\n",
    "\n",
    "-> Compiled model dir: {inf1_compiled_model_dir}\n",
    "            \"\"\")\n",
    "    \n",
    "    results, _, _ = inf1_benchmark_latency_max_threads(inf1_compiled_model_dir, \n",
    "                                                          user_batch_size = user_batch_size, \n",
    "                                                          num_model_copies = num_model_copies, \n",
    "                                                          threads_per_model = threads_per_model,\n",
    "                                                          use_cache=True)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "model_list = [{'batch_size':5, 'compiled_num_cores':1, 'saved_model_precision':'fp32', 'threads_per_model':1},\n",
    "             {'batch_size':5, 'compiled_num_cores':1, 'saved_model_precision':'fp32', 'threads_per_model':2},\n",
    "             {'batch_size':5, 'compiled_num_cores':1, 'saved_model_precision':'fp32', 'threads_per_model':4}]\n",
    "\n",
    "for m in model_list:\n",
    "    res = submit_inference_request(**m)\n",
    "    if results.empty:\n",
    "        results = res\n",
    "    else:\n",
    "        results = results.append(res)\n",
    "\n",
    "results = results.reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "model_list = [{'batch_size':5, 'compiled_num_cores':1, 'saved_model_precision':'fp16', 'threads_per_model':1},\n",
    "             {'batch_size':5, 'compiled_num_cores':1, 'saved_model_precision':'fp16', 'threads_per_model':2},\n",
    "                          {'batch_size':5, 'compiled_num_cores':1, 'saved_model_precision':'fp16', 'threads_per_model':4},\n",
    "                          {'batch_size':5, 'compiled_num_cores':1, 'saved_model_precision':'fp16', 'threads_per_model':8}]\n",
    "\n",
    "for m in model_list:\n",
    "    res = submit_inference_request(**m)\n",
    "    if results.empty:\n",
    "        results = res\n",
    "    else:\n",
    "        results = results.append(res)\n",
    "\n",
    "results = results.reset_index(drop=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index, iter_times_per_thread, pred_prob = map(list,zip(*[(f.result()['i_num'],f.result()['latency'],f.result()['probs/Softmax:0']) for f in future_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "pred_labels = []\n",
    "img_index = []\n",
    "iter_times_per_thread = []\n",
    "\n",
    "for f in future_list:\n",
    "    res = f.result()\n",
    "    img_index.append(res['i_num'])\n",
    "    iter_times_per_thread.append(res['latency'])\n",
    "    pred_labels.extend(np.argmax(res['probs/Softmax:0'], axis=1))\n",
    "\n",
    "print(time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(latency_per_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "compiled_num_cores = 1\n",
    "compiled_model_precision = 'fp32'\n",
    "\n",
    "infer_num_cores = 1\n",
    "threads_per_model = 6\n",
    "\n",
    "saved_model_dir = f'resnet50_saved_model_{compiled_model_precision}'\n",
    "parent_dir = 'resnet50_inf1_saved_models'\n",
    "\n",
    "compiled_model_dir = f'resnet50_{compiled_model_precision}_batch_{batch_size}_inf1_cores_{compiled_num_cores}'\n",
    "inf1_compiled_model_dir = os.path.join(parent_dir, compiled_model_dir)\n",
    "\n",
    "print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "print(f'compiled_model_precision: {compiled_model_precision}')\n",
    "\n",
    "results, latency_per_thread, pred_prob = inf1_predict_benchmark_multi_threaded(inf1_compiled_model_dir, \n",
    "                                      user_batch_size = batch_size*10, \n",
    "                                      infer_num_cores = infer_num_cores, \n",
    "                                      threads_per_model = threads_per_model,\n",
    "                                      use_cache=False, \n",
    "                                      warm_up=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(latency_per_thread[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "num_cores = 1\n",
    "compiled_model_precision = 'fp32'\n",
    "\n",
    "saved_model_dir = f'resnet50_saved_model_{compiled_model_precision}'\n",
    "parent_dir = 'resnet50_inf1_saved_models'\n",
    "\n",
    "compiled_model_dir = f'resnet50_{compiled_model_precision}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "inf1_compiled_model_dir = os.path.join(parent_dir, compiled_model_dir)\n",
    "\n",
    "print(f'inf1_compiled_model_dir: {inf1_compiled_model_dir}')\n",
    "print(f'compiled_model_precision: {compiled_model_precision}')\n",
    "\n",
    "results, latency_per_thread = inf1_predict_benchmark_multi_threaded(inf1_compiled_model_dir, \n",
    "                                      user_batch_size = batch_size*10, \n",
    "                                      infer_num_cores = 16, \n",
    "                                      threads_per_model = 1,\n",
    "                                      use_cache=True, \n",
    "                                      warm_up=10)\n",
    "\n",
    "results, latency_per_thread = inf1_predict_benchmark_multi_threaded(inf1_compiled_model_dir, \n",
    "                                      user_batch_size = batch_size*10, \n",
    "                                      infer_num_cores = 16, \n",
    "                                      threads_per_model = 2,\n",
    "                                      use_cache=True, \n",
    "                                      warm_up=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_attributes = [{'batch_size':1, 'num_cores':1},\n",
    "                    {'batch_size':5, 'num_cores':1},\n",
    "                    {'batch_size':1, 'num_cores':16, 'use_static_weights': True},\n",
    "                    {'batch_size':2, 'num_cores':16, 'use_static_weights': True},\n",
    "                    {'batch_size':1, 'num_cores':4},\n",
    "                    {'batch_size':5, 'num_cores':2},\n",
    "                    {'batch_size':5, 'num_cores':12}]\n",
    "\n",
    "saved_model_dir = 'resnet50_saved_model_fp16'\n",
    "parent_dir = 'resnet50_inf1_saved_models'\n",
    "    \n",
    "for model in model_attributes:\n",
    "    batch_size = model['batch_size']\n",
    "    num_cores = model['num_cores']\n",
    "    \n",
    "    compiled_model_dir = f'resnet50_{saved_model_dir[-4:]}_batch_{batch_size}_inf1_cores_{num_cores}'\n",
    "    inf1_compiled_model_dir = os.path.join(parent_dir, compiled_model_dir)\n",
    "    \n",
    "    if num_cores == 1:\n",
    "        infer_num_cores = 16\n",
    "    else:\n",
    "        infer_num_cores = 1\n",
    "        \n",
    "    print(inf1_compiled_model_dir)\n",
    "    \n",
    "    inf1_predict_benchmark_multi_threaded(inf1_compiled_model_dir, \n",
    "                                          user_batch_size = batch_size*10, \n",
    "                                          infer_num_cores = infer_num_cores, \n",
    "                                          use_cache=False, \n",
    "                                          warm_up=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boption = {'compiled_batch_size': 1, 'precision': 'auto_bfloat16', 'compiled_num_cores': 1}\n",
    "results, future_list, latency_per_thread = inf1_predict_benchmark_multi_threaded(boption, \n",
    "                                                                                 user_batch_size=50, \n",
    "                                                                                 infer_num_cores = 4, \n",
    "                                                                                 use_cache=False, \n",
    "                                                                                 warm_up=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boption = {'compiled_batch_size': 1, 'compiled_num_cores': 1, 'precision': 'fp16'}\n",
    "results, future_list, latency_per_thread = inf1_predict_benchmark_multi_threaded(boption, \n",
    "                                                                                 user_batch_size=50, \n",
    "                                                                                 infer_num_cores = 4, \n",
    "                                                                                 use_cache=False, \n",
    "                                                                                 warm_up=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boption = {'compiled_batch_size': 5, 'compiled_num_cores': 1, 'precision': 'fp16'}\n",
    "results, future_list, latency_per_thread = inf1_predict_benchmark_multi_threaded(boption, \n",
    "                                                                                 user_batch_size=50, \n",
    "                                                                                 infer_num_cores = 4, \n",
    "                                                                                 use_cache=False, \n",
    "                                                                                 warm_up=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boption = {'compiled_batch_size': 5, 'compiled_num_cores': 1, 'precision': 'fp16'}\n",
    "results, future_list, latency_per_thread = inf1_predict_benchmark_multi_threaded(boption, \n",
    "                                                                                 user_batch_size=50, \n",
    "                                                                                 infer_num_cores = 16, \n",
    "                                                                                 use_cache=False, \n",
    "                                                                                 warm_up=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boption = {'compiled_batch_size': 5, 'compiled_num_cores': 1, 'precision': 'fp16'}\n",
    "results, future_list, latency_per_thread = inf1_predict_benchmark_multi_threaded(boption, \n",
    "                                                                                 user_batch_size=50, \n",
    "                                                                                 infer_num_cores = 32, \n",
    "                                                                                 use_cache=False, \n",
    "                                                                                 warm_up=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boption = {'compiled_batch_size': 1, 'compiled_num_cores': 16, 'precision': 'fp16'}\n",
    "results, future_list, latency_per_thread = inf1_predict_benchmark_multi_threaded(boption, \n",
    "                                                                                 user_batch_size=50, \n",
    "                                                                                 infer_num_cores = 1, \n",
    "                                                                                 use_cache=False, \n",
    "                                                                                 warm_up=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = tf.contrib.predictor.from_saved_model('resnet50_inf1_saved_models/resnet50_fp16_batch_1_cores_1')\n",
    "resname = list(predictor.fetch_tensors.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_index, iter_times_per_thread, pred_prob = map(list,zip(*[(f.result()['i_num'],f.result()['latency'],f.result()[resname]) for f in future_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10/np.mean(iter_times_per_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [q for q in list(np.argmax(p, axis=1)) for p in pred_prob]\n",
    "a = []\n",
    "for p in pred_prob:\n",
    "    a.extend(np.argmax(p, axis=1))\n",
    "len(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(pred_prob, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_sorted = np.argsort(img_index)\n",
    "iter_times_sorted = [iter_times_per_thread[i] for i in idx_sorted]\n",
    "pred_prob_sorted = [pred_prob[i] for i in idx_sorted]\n",
    "\n",
    "idx_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/opt/aws/neuron/bin/neuron-cli reset\n",
    "# model_inf1 = tf.contrib.predictor.from_saved_model('resnet50_inf1_saved_models/resnet50_auto_bfloat16_batch_1_cores_1')\n",
    "# model_inf1 = tf.contrib.predictor.from_saved_model('resnet50_inf1_saved_models/resnet50_fp16_batch_1_cores_1')\n",
    "# model_inf1 = tf.contrib.predictor.from_saved_model('resnet50_inf1_saved_models/resnet50_fp16_batch_5_cores_1')\n",
    "# model_inf1 = tf.contrib.predictor.from_saved_model('resnet50_inf1_saved_models/resnet50_fp16_batch_1_cores_16')\n",
    "\n",
    "blist = [{'compiled_batch_size': 1, 'precision': 'auto_bfloat16', 'num_cores': 1},\n",
    "         {'compiled_batch_size': 1, 'precision': 'fp16',  'num_cores': 1},\n",
    "         {'compiled_batch_size': 5, 'precision': 'fp16', 'num_cores': 1},\n",
    "         {'compiled_batch_size': 1, 'precision': 'fp16', 'num_cores': 16},]\n",
    "\n",
    "results, iter_times = inf1_predict_benchmark(blist[3], user_batch_size=10, use_cache = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = lambda boption: f'inf1_{boption[\"precision\"]}_batchcompiled_{boption[\"compiled_batch_size\"]}_batchuser_{boption[\"user_batch_size\"]}'\n",
    "use_cache = False\n",
    "\n",
    "for boption in blist:\n",
    "    model_path = f'resnet50_inf1_saved_models/resnet50_{boption['precision']}_{boption['compiled_batch_size']}'\n",
    "    dataset = get_dataset(batch_size = boption['user_batch_size'], use_cache)\n",
    "    if use_cache:\n",
    "        print('Start caching ...')\n",
    "        start_time = time.time()\n",
    "        for _ in dataset:\n",
    "            continue\n",
    "        print(f'Caching finished: {time.time()-start_time} sec')\n",
    "    \n",
    "    res, it = inf1_predict_benchmark(dataset, model_path, **boption)\n",
    "    iter_ds = pd.concat([iter_ds, pd.DataFrame(it, columns=[col_name(boption)])], axis=1)\n",
    "    if results.empty:\n",
    "        results = res\n",
    "    else:\n",
    "        results = results.append(res)\n",
    "    display(results)\n",
    "\n",
    "results = results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_aws_neuron_tensorflow_p36)",
   "language": "python",
   "name": "conda_aws_neuron_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
