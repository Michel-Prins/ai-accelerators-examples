{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example was tested on the following NVIDIA Docker image: nvcr.io/nvidia/tensorflow:20.08-tf2-py3\n",
    "# !nvidia-docker run --shm-size 8g --ulimit memlock=-1 -it -v $PWD:/examples -v ~/.aws/:/.aws --network=host nvcr.io/nvidia/tensorflow:20.08-tf2-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your imagenet TFRecord using the following:\n",
    "# https://github.com/tensorflow/models/blob/archive/research/inception/inception/data/download_and_preprocess_imagenet.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip -q\n",
    "# !pip install matplotlib pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT version: (7, 1, 3)\n",
      "TensorFlow version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from functools import partial\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.python.saved_model import tag_constants, signature_constants\n",
    "from tensorflow.python.framework import convert_to_constants\n",
    "\n",
    "from tensorflow.compiler.tf2tensorrt.wrap_py_utils import get_linked_tensorrt_version\n",
    "print(f\"TensorRT version: {get_linked_tensorrt_version()}\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Keras Resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_save_resnet50_model(saved_model_dir = 'resnet50_saved_model'):\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    shutil.rmtree(saved_model_dir, ignore_errors=True)\n",
    "    model.save(saved_model_dir, include_optimizer=False, save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: resnet50_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = 'resnet50_saved_model' \n",
    "load_save_resnet50_model(saved_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_image_record(record):\n",
    "    feature_map = {'image/encoded': tf.io.FixedLenFeature([], tf.string, ''),\n",
    "                  'image/class/label': tf.io.FixedLenFeature([1], tf.int64, -1),\n",
    "                  'image/class/text': tf.io.FixedLenFeature([], tf.string, '')}\n",
    "    obj = tf.io.parse_single_example(serialized=record, features=feature_map)\n",
    "    imgdata = obj['image/encoded']\n",
    "    label = tf.cast(obj['image/class/label'], tf.int32)   \n",
    "    label_text = tf.cast(obj['image/class/text'], tf.string)   \n",
    "    return imgdata, label, label_text\n",
    "\n",
    "def val_preprocessing(record):\n",
    "    imgdata, label, label_text = deserialize_image_record(record)\n",
    "    label -= 1\n",
    "    image = tf.io.decode_jpeg(imgdata, channels=3, \n",
    "                              fancy_upscaling=False, \n",
    "                              dct_method='INTEGER_FAST')\n",
    "\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.float32)\n",
    "    width = tf.cast(shape[1], tf.float32)\n",
    "    side = tf.cast(tf.convert_to_tensor(256, dtype=tf.int32), tf.float32)\n",
    "\n",
    "    scale = tf.cond(tf.greater(height, width),\n",
    "                  lambda: side / width,\n",
    "                  lambda: side / height)\n",
    "    \n",
    "    new_height = tf.cast(tf.math.rint(height * scale), tf.int32)\n",
    "    new_width = tf.cast(tf.math.rint(width * scale), tf.int32)\n",
    "    \n",
    "    image = tf.image.resize(image, [new_height, new_width], method='bicubic')\n",
    "    image = tf.image.resize_with_crop_or_pad(image, 224, 224)\n",
    "    \n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    \n",
    "    return image, label, label_text\n",
    "\n",
    "def get_dataset(batch_size, use_cache=False):\n",
    "    data_dir = '/examples/datasets/*'\n",
    "    files = tf.io.gfile.glob(os.path.join(data_dir))\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "    \n",
    "    dataset = dataset.map(map_func=val_preprocessing, num_parallel_calls=8)\n",
    "    dataset = dataset.batch(batch_size=batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.repeat(count=1)\n",
    "    \n",
    "    if use_cache:\n",
    "        shutil.rmtree('tfdatacache', ignore_errors=True)\n",
    "        os.mkdir('tfdatacache')\n",
    "        dataset = dataset.cache(f'./tfdatacache/imagenet_val')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using GPU + Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Images 5120/50000. Average i/s 1202.2403815597772\n",
      "Images 10112/50000. Average i/s 1255.4613821650041\n",
      "Images 15104/50000. Average i/s 1274.7982025827173\n",
      "Images 20096/50000. Average i/s 1282.2455741806853\n",
      "Images 25088/50000. Average i/s 1286.8815339138637\n",
      "Images 30080/50000. Average i/s 1292.0688698725226\n",
      "Images 35072/50000. Average i/s 1295.2494914105964\n",
      "Images 40064/50000. Average i/s 1296.9882964127578\n",
      "Images 45056/50000. Average i/s 1299.6527953350485\n",
      "CPU times: user 9min 48s, sys: 59.1 s, total: 10min 47s\n",
      "Wall time: 3min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = tf.keras.models.load_model(saved_model_dir)\n",
    "batch_size = 128\n",
    "display_every = 5000\n",
    "display_threshold = display_every\n",
    "\n",
    "pred_labels = []\n",
    "actual_labels = []\n",
    "iter_times = []\n",
    "\n",
    "# Get the tf.data.TFRecordDataset object for the ImageNet2012 validation dataset\n",
    "dataset = get_dataset(batch_size)  \n",
    "\n",
    "for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "    start_time = time.time()\n",
    "    pred_prob_keras = model(validation_ds)\n",
    "    iter_times.append(time.time() - start_time)\n",
    "       \n",
    "    actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "    pred_labels.extend(list(np.argmax(pred_prob_keras, axis=1)))\n",
    "    \n",
    "    if i*batch_size >= display_threshold:\n",
    "        print(f'Images {i*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "        display_threshold+=display_every\n",
    "\n",
    "iter_times = np.array(iter_times)\n",
    "acc_keras_gpu = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keras_gpu_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_type</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.74956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>46.5699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>1300.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>141.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>119.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>482.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>97.7492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>73.1673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        keras_gpu_128\n",
       "instance_type            g4dn.2xlarge\n",
       "user_batch_size                   128\n",
       "accuracy                      0.74956\n",
       "prediction_time               46.5699\n",
       "images_per_sec_mean           1300.16\n",
       "images_per_sec_std            141.432\n",
       "latency_mean                  119.105\n",
       "latency_99th_percentile       482.203\n",
       "latency_median                97.7492\n",
       "latency_min                   73.1673"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(columns = [f'keras_gpu_{batch_size}'])\n",
    "results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "results.loc['user_batch_size']         = [batch_size]\n",
    "results.loc['accuracy']                = [acc_keras_gpu]\n",
    "results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict using GPU + TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fn(batch_size, dataset):\n",
    "    for i, (build_image, _, _) in enumerate(dataset):\n",
    "        if i > 1:\n",
    "            break\n",
    "        yield (build_image,)\n",
    "\n",
    "def calibrate_fn(n_calib, batch_size, dataset):\n",
    "    for i, (calib_image, _, _) in enumerate(dataset):\n",
    "        if i > n_calib // batch_size:\n",
    "            break\n",
    "        yield (calib_image,)\n",
    "\n",
    "def build_tensorrt_engine(precision, batch_size, dataset):\n",
    "    from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "    conversion_params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(precision_mode=precision.upper(),\n",
    "                                                                   max_workspace_size_bytes=(1<<32),\n",
    "                                                                   maximum_cached_engines=2)\n",
    "    converter = trt.TrtGraphConverterV2(input_saved_model_dir='resnet50_saved_model',\n",
    "                                        conversion_params=conversion_params)\n",
    "    \n",
    "    if precision.lower() == 'int8':\n",
    "        n_calib=100\n",
    "        converter.convert(calibration_input_fn=partial(calibrate_fn, n_calib, batch_size, \n",
    "                                                       dataset.shuffle(buffer_size=n_calib, reshuffle_each_iteration=True)))\n",
    "    else:\n",
    "        converter.convert()\n",
    "        \n",
    "    trt_compiled_model_dir = f'resnet50_trt_saved_models/resnet50_{precision}_{batch_size}'\n",
    "    shutil.rmtree(trt_compiled_model_dir, ignore_errors=True)\n",
    "\n",
    "    converter.build(input_fn=partial(build_fn, batch_size, dataset))\n",
    "    converter.save(output_saved_model_dir=trt_compiled_model_dir)\n",
    "    print(f'\\nOptimized for {precision} and batch size {batch_size}, directory:{trt_compiled_model_dir}\\n')\n",
    "    return trt_compiled_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_predict_benchmark(precision, batch_size, use_cache=False, display_every=100, warm_up=10):\n",
    "\n",
    "    print('\\n=======================================================')\n",
    "    print(f'Benchmark results for precision: {precision}, batch size: {batch_size}')\n",
    "    print('=======================================================\\n')\n",
    "    \n",
    "    dataset = get_dataset(batch_size)\n",
    "    \n",
    "    # If caching is enabled, cache dataset for better i/o performance\n",
    "    if use_cache:\n",
    "        print('Caching dataset ...')\n",
    "        start_time = time.time()\n",
    "        for (img,_,_) in dataset:\n",
    "            continue\n",
    "        print(f'Finished caching {time.time() - start_time}')\n",
    "    \n",
    "    trt_compiled_model_dir = build_tensorrt_engine(precision, batch_size, dataset)\n",
    "    saved_model_trt = tf.saved_model.load(trt_compiled_model_dir, tags=[tag_constants.SERVING])\n",
    "    model_trt = saved_model_trt.signatures[signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
    "    \n",
    "    pred_labels = []\n",
    "    actual_labels = []\n",
    "    iter_times = []\n",
    "    \n",
    "    display_every = 5000\n",
    "    display_threshold = display_every\n",
    "    initial_time = time.time()\n",
    "    \n",
    "    walltime_start = time.time()\n",
    "    for i, (validation_ds, batch_labels, _) in enumerate(dataset):\n",
    "        if i==0:\n",
    "            for w in range(warm_up):\n",
    "                _ = model_trt(validation_ds);\n",
    "                \n",
    "        start_time = time.time()\n",
    "        trt_results = model_trt(validation_ds);\n",
    "        iter_times.append(time.time() - start_time)\n",
    "        \n",
    "        actual_labels.extend(label for label_list in batch_labels.numpy() for label in label_list)\n",
    "        pred_labels.extend(list(tf.argmax(trt_results['predictions'], axis=1).numpy()))\n",
    "        if (i)*batch_size >= display_threshold:\n",
    "            print(f'Images {(i)*batch_size}/50000. Average i/s {np.mean(batch_size/np.array(iter_times[-display_every:]))}')\n",
    "            display_threshold+=display_every\n",
    "    \n",
    "    print(f'Wall time: {time.time() - walltime_start}')\n",
    "\n",
    "    acc_trt = np.sum(np.array(actual_labels) == np.array(pred_labels))/len(actual_labels)\n",
    "    iter_times = np.array(iter_times)\n",
    "   \n",
    "    results = pd.DataFrame(columns = [f'trt_{precision}_{batch_size}'])\n",
    "    results.loc['instance_type']           = [requests.get('http://169.254.169.254/latest/meta-data/instance-type').text]\n",
    "    results.loc['user_batch_size']         = [batch_size]\n",
    "    results.loc['accuracy']                = [acc_trt]\n",
    "    results.loc['prediction_time']         = [np.sum(iter_times)]\n",
    "    results.loc['images_per_sec_mean']     = [np.mean(batch_size / iter_times)]\n",
    "    results.loc['images_per_sec_std']      = [np.std(batch_size / iter_times, ddof=1)]\n",
    "    results.loc['latency_mean']            = [np.mean(iter_times) * 1000]\n",
    "    results.loc['latency_99th_percentile'] = [np.percentile(iter_times, q=99, interpolation=\"lower\") * 1000]\n",
    "    results.loc['latency_median']          = [np.median(iter_times) * 1000]\n",
    "    results.loc['latency_min']             = [np.min(iter_times) * 1000]\n",
    "    display(results.T)\n",
    "   \n",
    "    return results, iter_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark sweep combinations:\n",
      "{'batch_size': 128, 'precision': 'fp32'}\n",
      "{'batch_size': 128, 'precision': 'int8'}\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "bench_options = {\n",
    "    'batch_size': [128],\n",
    "    'precision': ['fp32', 'int8']\n",
    "}\n",
    "\n",
    "bname, bval = zip(*bench_options.items())\n",
    "blist = [dict(zip(bname, h)) for h in itertools.product(*bval)]\n",
    "\n",
    "print('Benchmark sweep combinations:')\n",
    "for b in blist:\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for precision: fp32, batch size: 128\n",
      "=======================================================\n",
      "\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Assets written to: resnet50_trt_saved_models/resnet50_fp32_128/assets\n",
      "\n",
      "Optimized for fp32 and batch size 128, directory:resnet50_trt_saved_models/resnet50_fp32_128\n",
      "\n",
      "Images 5120/50000. Average i/s 7670.863059439031\n",
      "Images 10112/50000. Average i/s 7708.883268765703\n",
      "Images 15104/50000. Average i/s 7781.459817044685\n",
      "Images 20096/50000. Average i/s 7866.970004647157\n",
      "Images 25088/50000. Average i/s 7847.518386147604\n",
      "Images 30080/50000. Average i/s 7894.069897762841\n",
      "Images 35072/50000. Average i/s 7891.932053748691\n",
      "Images 40064/50000. Average i/s 7853.895544474464\n",
      "Images 45056/50000. Average i/s 7832.923218960731\n",
      "Wall time: 119.47140908241272\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trt_fp32_128</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>128</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>6.75721</td>\n",
       "      <td>7869.37</td>\n",
       "      <td>1240.29</td>\n",
       "      <td>17.2819</td>\n",
       "      <td>23.9022</td>\n",
       "      <td>16.0117</td>\n",
       "      <td>8.42524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             instance_type user_batch_size accuracy prediction_time  \\\n",
       "trt_fp32_128  g4dn.2xlarge             128  0.74956         6.75721   \n",
       "\n",
       "             images_per_sec_mean images_per_sec_std latency_mean  \\\n",
       "trt_fp32_128             7869.37            1240.29      17.2819   \n",
       "\n",
       "             latency_99th_percentile latency_median latency_min  \n",
       "trt_fp32_128                 23.9022        16.0117     8.42524  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================================\n",
      "Benchmark results for precision: int8, batch size: 128\n",
      "=======================================================\n",
      "\n",
      "INFO:tensorflow:Linked TensorRT version: (7, 1, 3)\n",
      "INFO:tensorflow:Loaded TensorRT version: (7, 1, 3)\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).trt_engine_resources.TRTEngineOp_0_0._serialized_trt_resource_filename\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Assets written to: resnet50_trt_saved_models/resnet50_int8_128/assets\n",
      "\n",
      "Optimized for int8 and batch size 128, directory:resnet50_trt_saved_models/resnet50_int8_128\n",
      "\n",
      "Images 5120/50000. Average i/s 7396.425219329722\n",
      "Images 10112/50000. Average i/s 7541.030847957469\n",
      "Images 15104/50000. Average i/s 7576.9405442854595\n",
      "Images 20096/50000. Average i/s 7608.913582959295\n",
      "Images 25088/50000. Average i/s 7650.61839783195\n",
      "Images 30080/50000. Average i/s 7707.159023536961\n",
      "Images 35072/50000. Average i/s 7731.482805650456\n",
      "Images 40064/50000. Average i/s 7743.64490248324\n",
      "Images 45056/50000. Average i/s 7757.7598333462\n",
      "Wall time: 63.807910203933716\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_type</th>\n",
       "      <th>user_batch_size</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <th>latency_mean</th>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <th>latency_median</th>\n",
       "      <th>latency_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trt_int8_128</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>128</td>\n",
       "      <td>0.74816</td>\n",
       "      <td>6.5471</td>\n",
       "      <td>7764.95</td>\n",
       "      <td>945.311</td>\n",
       "      <td>16.7445</td>\n",
       "      <td>22.0578</td>\n",
       "      <td>16.4688</td>\n",
       "      <td>8.5845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             instance_type user_batch_size accuracy prediction_time  \\\n",
       "trt_int8_128  g4dn.2xlarge             128  0.74816          6.5471   \n",
       "\n",
       "             images_per_sec_mean images_per_sec_std latency_mean  \\\n",
       "trt_int8_128             7764.95            945.311      16.7445   \n",
       "\n",
       "             latency_99th_percentile latency_median latency_min  \n",
       "trt_int8_128                 22.0578        16.4688      8.5845  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keras_gpu_128</th>\n",
       "      <th>trt_fp32_128</th>\n",
       "      <th>trt_int8_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_type</th>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "      <td>g4dn.2xlarge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_batch_size</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.74956</td>\n",
       "      <td>0.74956</td>\n",
       "      <td>0.74816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction_time</th>\n",
       "      <td>46.5699</td>\n",
       "      <td>6.75721</td>\n",
       "      <td>6.5471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_mean</th>\n",
       "      <td>1300.16</td>\n",
       "      <td>7869.37</td>\n",
       "      <td>7764.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images_per_sec_std</th>\n",
       "      <td>141.432</td>\n",
       "      <td>1240.29</td>\n",
       "      <td>945.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_mean</th>\n",
       "      <td>119.105</td>\n",
       "      <td>17.2819</td>\n",
       "      <td>16.7445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_99th_percentile</th>\n",
       "      <td>482.203</td>\n",
       "      <td>23.9022</td>\n",
       "      <td>22.0578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_median</th>\n",
       "      <td>97.7492</td>\n",
       "      <td>16.0117</td>\n",
       "      <td>16.4688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_min</th>\n",
       "      <td>73.1673</td>\n",
       "      <td>8.42524</td>\n",
       "      <td>8.5845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        keras_gpu_128  trt_fp32_128  trt_int8_128\n",
       "instance_type            g4dn.2xlarge  g4dn.2xlarge  g4dn.2xlarge\n",
       "user_batch_size                   128           128           128\n",
       "accuracy                      0.74956       0.74956       0.74816\n",
       "prediction_time               46.5699       6.75721        6.5471\n",
       "images_per_sec_mean           1300.16       7869.37       7764.95\n",
       "images_per_sec_std            141.432       1240.29       945.311\n",
       "latency_mean                  119.105       17.2819       16.7445\n",
       "latency_99th_percentile       482.203       23.9022       22.0578\n",
       "latency_median                97.7492       16.0117       16.4688\n",
       "latency_min                   73.1673       8.42524        8.5845"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iter_ds = pd.DataFrame()\n",
    "col_name = lambda boption: f'trt_{boption[\"precision\"]}_{boption[\"batch_size\"]}'\n",
    "\n",
    "for boption in blist:\n",
    "    res, it = trt_predict_benchmark(**boption)\n",
    "    iter_ds = pd.concat([iter_ds, pd.DataFrame(it, columns=[col_name(boption)])], axis=1)\n",
    "    results = pd.concat([results, res], axis=1)\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
